source("../../utilities/load_library.R")
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE,
fig.width=14.9/2.54,
dpi=300,
fig.height=10/2.54)
library(dplyr)
library(tidyr)
library(readxl)
library(yaml)
cred=read_yaml("../../../credentials.yml")
con_wgeel = dbConnect(Postgres(), dbname=cred$dbname,host=cred$host,port=cred$port,user=cred$user, password=cred$password)
source("../../utilities/load_library.R")
knitr::opts_chunk$set(
echo = TRUE,
warning = FALSE,
message = FALSE,
fig.width = 14.9 / 2.54,
dpi = 300,
fig.height = 10 / 2.54)
source("../../utilities/load_library.R")
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE,
fig.width=14.9/2.54,
dpi=300,
fig.height=10/2.54)
load_library("RPostgres")
load_library("dplyr")
load_library("tidyr")
load_library("readxl")
load_library("yaml")
cred=read_yaml("../../../credentials.yml")
con_wgeel = dbConnect(Postgres(), dbname=cred$dbname,host=cred$host,port=cred$port,user=cred$user, password=cred$password)
source("../../utilities/load_library.R")
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE,
fig.width=14.9/2.54,
dpi=300,
fig.height=10/2.54)
load_library("RPostgres")
load_library("dplyr")
load_library("tidyr")
load_library("readxl")
load_library("yaml")
cred=read_yaml("../../../credentials.yml")
con_wgeel = dbConnect(Postgres(), dbname=cred$dbname,host=cred$host,port=cred$port,user=cred$user, password=cred$password)
query='SELECT
das_id,
das_value,
das_effort,
das_year,
das_comment,
ser_id,
cou_order,
ser_nameshort,
ser_area_division,
ser_qal_id,
ser_hty_code,
ser_emu_nameshort,
ser_uni_code,
ser_cou_code,
ser_comment,
sam_samplingtype,
ser_sam_id, ser_distanceseakm, ser_method, ser_sam_gear, ser_restocking,
das_qal_id,
das_last_update,
f_subarea,
lfs_code,
lfs_name
from datawg.t_dataseries_das
join datawg.t_series_ser on das_ser_id=ser_id
left join ref.tr_samplingtype_sam on ser_sam_id=sam_id
left join ref.tr_lifestage_lfs on ser_lfs_code=lfs_code
left join ref.tr_faoareas on ser_area_division=f_division
left join ref.tr_country_cou on cou_code=ser_cou_code
where ser_typ_id in (2,3) and das_value is not null and  (ser_qal_id IS NULL OR ser_qal_id IN (0,1,2,4)) and (das_qal_id IS NULL OR das_qal_id IN (1,2,4))'
mydata = dbGetQuery(con_wgeel,query) # Get yellow and silver eel time series from WGEEL database
dbDisconnect(con_wgeel) #disconnect from WGEEL database
d.effort = read_xlsx("data/effort overview.xlsx") #Load overview of effort type and availability that was manually made at WGEEL 2023
d.ecoregion = read.csv2("data/points_with_ecoregions_forRob.csv") %>% #Load data on ecoregion of dataseries
rename(ecoregion = new_Ecoreg)
####################
### Get data in right format
data <- mydata %>%
filter(lfs_code == "S") %>% #Filter data down to silver eel timeseries
arrange(ser_nameshort, das_year) %>% # Sort data for better overview
left_join(d.ecoregion %>% select(ser_id, ecoregion, distance_to_ecoregion)) # Add ecoregion info
####################
### Filter data down to relevant silver eel series
# Filter data according to time series length, and the availability of effort data
# If no data on effort is known, then the series cannot be used to analyse trends in abundance/CPUE.
# Sometimes, no effort data is given because all silver eel passing through a river are sampled. This data is kept here,
# perhaps advise in next year's data call to set such effort equal to 1 in the das_effort column
min.length = 10 #minimum time-series length, delete series with fewer number of years
#Overview table to be used in the subgroup text to show which series were kept and which were discarded
t.filterchoice <- data %>%
count(ser_nameshort, ser_method) %>% #filter data down to series name and method, while counting time series length
left_join(d.effort %>% select(ser_nameshort, effort, notes)) %>% #Add information on effort type/availability
mutate(filtered = case_when(
n < min.length ~ "Dropped", # Set a variable specifying if the column should be filtered out based on time-series length
effort == "unknown" ~ "Dropped", # Drop series with unknown effort
ser_nameshort %in% c("NorwS", "WepeS") ~ "Dropped", #These two series have had trouble reporting in recent years, data for those years not reliable, drop until issue is resolved.
TRUE ~ "Kept"
),
reason.dropped = case_when(
n < min.length ~ paste("Number of years fewer than",min.length, sep = " "),
effort == "unknown" ~ "No effort given",
ser_nameshort %in% c("NorwS", "WepeS") ~ "Inconsistencies in data",
TRUE ~ ""
)
)
### NOTE: LevS reports no effort (assumed constant effort), but lists multiple years with deviations in sampling times, and thus different effort. Choose what to do with those.
# Apply the filter to the data, calculate CPUE, process data to output format
d.cpue <- data %>%
left_join(t.filterchoice %>% select(ser_nameshort, filtered)) %>% #add filter choice
filter(filtered != "Dropped") %>% #filter out selected series
mutate(cpue = if_else(is.na(das_effort), das_value, das_value/das_effort)) %>% #calculate cpue if effort data is given, otherwise assume that das_value is already CPUE
select(das_id, das_year, cpue, das_value, das_effort, ser_id, ser_nameshort, ser_hty_code, ser_emu_nameshort, ser_cou_code, ser_distanceseakm, ser_restocking, ecoregion, distance_to_ecoregion, das_qal_id, ser_qal_id)
dbDisconnect(con_wgeel)
d.cpue
table <- t.filterchoice %>%
select(!ser_method) %>% # drop method description
mutate(notes = ifelse(is.na(notes), "", notes)) %>% #change NAs to blanks in notes
rename("Series name" = ser_nameshort, #rename table headers
"Years (n)" = n,
"Effort data" = effort,
"Filtered" = filtered,
"Drop reason" = reason.dropped,
"Comments" = notes)
knitr::kable(table, format="html")
head(d.cpue)
silver_arr <-d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)%>%
pivot_wider(id_cols=c(ser_nameshort,das_year),names_from=das_year,values_from=cpue)
silver_arr <-d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)%>%
pivot_wider(id_cols=c(ser_nameshort,das_year),values_from=cpue)
d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)
silver_arr <-d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)%>%
pivot_wider(names_from=ser_nameshort,values_from=cpue)
silver_arr
??MARSS
graph_serie = function(data,choose_variable=c("das_value","cpue"))
{
data_good_format = as.tibble(data) %>% pivot_longer(!das_year, names_to = "ser_nameshort", values_to = choose_variable)
graph = 	ggplot(data_good_format,  aes(x = das_year, y = get(choose_variable)))  + geom_line()  + geom_point(color = "blue") + facet_wrap(~ ser_nameshort, scales = "free_y") +  xlab("Year") + ylab("Abundance")
return(graph)
}
graph_serie(silver_arr, "das_value")
load_library("tibble")
graph_serie(silver_arr, "das_value")
load_library("gpplot2")
load_library("ggplot2")
graph_serie = function(data,choose_variable=c("das_value","cpue"))
{
data_good_format = as_tibble(data) %>% pivot_longer(!das_year, names_to = "ser_nameshort", values_to = choose_variable)
graph = 	ggplot(data_good_format,  aes(x = das_year, y = get(choose_variable)))  + geom_line()  + geom_point(color = "blue") + facet_wrap(~ ser_nameshort, scales = "free_y") +  xlab("Year") + ylab("Abundance")
return(graph)
}
graph_serie(silver_arr, "das_value")
S=c("diagonal and equal")
nbtrend=1:10
expe=expand.grid(S=S,nbtrend=nbtrend)
S=c("diagonal and unequal")
nbtrend=1:5
expe=rbind(expe, expand.grid(S=S,nbtrend=nbtrend))
source("../DFA_functions.R")
silver_arr <-d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)%>%
pivot_wider(names_from=ser_nameshort,values_from=cpue)
silver_arr <-d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)%>%
pivot_wider(names_from=ser_nameshort,values_from=cpue)
S=c("diagonal and equal")
nbtrend=1:10
expe=expand.grid(S=S,nbtrend=nbtrend)
S=c("diagonal and unequal")
nbtrend=1:5
expe=rbind(expe, expand.grid(S=S,nbtrend=nbtrend))
#S=c("unconstrained")
#nbtrend=1:3
#expe=rbind(expe, expand.grid(S=S,nbtrend=nbtrend))
# lancement des DFA
modele_S_DFA_nolog = run_DFA(silver_arr, expe, log = F)
source("../../utilities/load_library.R")
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE,
fig.width=14.9/2.54,
dpi=300,
fig.height=10/2.54)
load_library("RPostgres")
load_library("dplyr")
load_library("tidyr")
load_library("readxl")
load_library("yaml")
cred=read_yaml("../../../credentials.yml")
con_wgeel = dbConnect(Postgres(), dbname=cred$dbname,host=cred$host,port=cred$port,user=cred$user, password=cred$password)
query='SELECT
das_id,
das_value,
das_effort,
das_year,
das_comment,
ser_id,
cou_order,
ser_nameshort,
ser_area_division,
ser_qal_id,
ser_hty_code,
ser_emu_nameshort,
ser_uni_code,
ser_cou_code,
ser_comment,
sam_samplingtype,
ser_sam_id, ser_distanceseakm, ser_method, ser_sam_gear, ser_restocking,
das_qal_id,
das_last_update,
f_subarea,
lfs_code,
lfs_name
from datawg.t_dataseries_das
join datawg.t_series_ser on das_ser_id=ser_id
left join ref.tr_samplingtype_sam on ser_sam_id=sam_id
left join ref.tr_lifestage_lfs on ser_lfs_code=lfs_code
left join ref.tr_faoareas on ser_area_division=f_division
left join ref.tr_country_cou on cou_code=ser_cou_code
where ser_typ_id in (2,3) and das_value is not null and  (ser_qal_id IS NULL OR ser_qal_id IN (0,1,2,4)) and (das_qal_id IS NULL OR das_qal_id IN (1,2,4))'
mydata = dbGetQuery(con_wgeel,query) # Get yellow and silver eel time series from WGEEL database
dbDisconnect(con_wgeel) #disconnect from WGEEL database
d.effort = read_xlsx("data/effort overview.xlsx") #Load overview of effort type and availability that was manually made at WGEEL 2023
d.ecoregion = read.csv2("data/points_with_ecoregions_forRob.csv") %>% #Load data on ecoregion of dataseries
rename(ecoregion = new_Ecoreg)
####################
### Get data in right format
data <- mydata %>%
filter(lfs_code == "S") %>% #Filter data down to silver eel timeseries
arrange(ser_nameshort, das_year) %>% # Sort data for better overview
left_join(d.ecoregion %>% select(ser_id, ecoregion, distance_to_ecoregion)) # Add ecoregion info
####################
### Filter data down to relevant silver eel series
# Filter data according to time series length, and the availability of effort data
# If no data on effort is known, then the series cannot be used to analyse trends in abundance/CPUE.
# Sometimes, no effort data is given because all silver eel passing through a river are sampled. This data is kept here,
# perhaps advise in next year's data call to set such effort equal to 1 in the das_effort column
min.length = 10 #minimum time-series length, delete series with fewer number of years
#Overview table to be used in the subgroup text to show which series were kept and which were discarded
t.filterchoice <- data %>%
count(ser_nameshort, ser_method) %>% #filter data down to series name and method, while counting time series length
left_join(d.effort %>% select(ser_nameshort, effort, notes)) %>% #Add information on effort type/availability
mutate(filtered = case_when(
n < min.length ~ "Dropped", # Set a variable specifying if the column should be filtered out based on time-series length
effort == "unknown" ~ "Dropped", # Drop series with unknown effort
ser_nameshort %in% c("NorwS", "WepeS") ~ "Dropped", #These two series have had trouble reporting in recent years, data for those years not reliable, drop until issue is resolved.
TRUE ~ "Kept"
),
reason.dropped = case_when(
n < min.length ~ paste("Number of years fewer than",min.length, sep = " "),
effort == "unknown" ~ "No effort given",
ser_nameshort %in% c("NorwS", "WepeS") ~ "Inconsistencies in data",
TRUE ~ ""
)
)
### NOTE: LevS reports no effort (assumed constant effort), but lists multiple years with deviations in sampling times, and thus different effort. Choose what to do with those.
# Apply the filter to the data, calculate CPUE, process data to output format
d.cpue <- data %>%
left_join(t.filterchoice %>% select(ser_nameshort, filtered)) %>% #add filter choice
filter(filtered != "Dropped") %>% #filter out selected series
mutate(cpue = if_else(is.na(das_effort), das_value, das_value/das_effort)) %>% #calculate cpue if effort data is given, otherwise assume that das_value is already CPUE
select(das_id, das_year, cpue, das_value, das_effort, ser_id, ser_nameshort, ser_hty_code, ser_emu_nameshort, ser_cou_code, ser_distanceseakm, ser_restocking, ecoregion, distance_to_ecoregion, das_qal_id, ser_qal_id)
dbDisconnect(con_wgeel)
load_library("MARSS")
source("../DFA_functions.R")
silver_arr <-d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)%>%
pivot_wider(names_from=ser_nameshort,values_from=cpue)
S=c("diagonal and equal")
nbtrend=1:10
expe=expand.grid(S=S,nbtrend=nbtrend)
S=c("diagonal and unequal")
nbtrend=1:5
expe=rbind(expe, expand.grid(S=S,nbtrend=nbtrend))
#S=c("unconstrained")
#nbtrend=1:3
#expe=rbind(expe, expand.grid(S=S,nbtrend=nbtrend))
# run DFA
modele_S_DFA_nolog = run_DFA(silver_arr, expe, log = F)
results_dfa = summary_models(modele_S_DFA_nolog)
results_dfa
results_dfa
x<-table_summary_models(results_dfa)
x
graph_dfa<-graph_summary_models(results_dfa)
graph_dfa
best_fit_dfa = best_DFA(modele_S_DFA_nolog)
ggplot2::autoplot(best_fit_dfa, plot.type = "std.model.resids.ytT")
ggplot2::autoplot(best_fit_dfal, plot.type = "qqplot.std.model.resids.ytt1")
ggplot2::autoplot(best_fit_dfa, plot.type = "qqplot.std.model.resids.ytt1")
formatted_matrices_dfa= results_DFA(best_fit_dfa)
formatted_matrices_dfa
signe_trend<-c()
for(i in 1:ncol(unlist(formatted_matrices_dfa$Z.conf$Z))){
if(
length(formatted_matrices_dfa$Z.conf$Z[,i][formatted_matrices_dfa$Z.conf$Z[,i]>0]) <
length(formatted_matrices_dfa$Z.conf$Z[,i][formatted_matrices_dfa$Z.conf$Z[,i]<0]))
{signe_trend[i]<- -1}
else{signe_trend[i]<- 1}
}
signe_trend
graph_Z(formatted_matrices_dfa$Z.conf, signe_trend = signe_trend)
graph_Z(formatted_matrices_dfa$Z.conf, sign_trends = signe_trend)
graph_trends(trends = formatted_matrices_dfa$trends, year, sign_trends = signe_trend)
graph_trends(trends = formatted_matrices_dfa$trends, das_year, sign_trends = signe_trend)
sort(unique(silver_arr$das_year))
graph_trends(trends = formatted_matrices_dfa$trends, sort(unique(silver_arr$das_year)), sign_trends = signe_trend)
d.cpue%>%filter(das_year=>1980)
d.cpue%>%filter(das_year>1979)
d.cpue<-d.cpue%>%filter(das_year>1979)
silver_arr <-d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)%>%
pivot_wider(names_from=ser_nameshort,values_from=cpue)
silver_arr
S=c("diagonal and equal")
nbtrend=1:5
expe=expand.grid(S=S,nbtrend=nbtrend)
S=c("diagonal and unequal")
nbtrend=1:5
expe=rbind(expe, expand.grid(S=S,nbtrend=nbtrend))
#S=c("unconstrained")
#nbtrend=1:3
#expe=rbind(expe, expand.grid(S=S,nbtrend=nbtrend))
# run DFA
modele_S_DFA_nolog = run_DFA(silver_arr, expe, log = F)
load_library("RPostgres")
load_library("dplyr")
load_library("tidyr")
load_library("readxl")
load_library("yaml")
load_library("ggplot2")
cred=read_yaml("../../../credentials.yml")
con_wgeel = dbConnect(Postgres(), dbname=cred$dbname,host=cred$host,port=cred$port,user=cred$user, password=cred$password)
results_dfa = summary_models(modele_S_DFA_nolog)
x<-table_summary_models(results_dfa)
graph_dfa<-graph_summary_models(results_dfa)
graph_dfa
best_fit_dfa = best_DFA(modele_S_DFA_nolog)
best_fit_dfa
ggplot2::autoplot(best_fit_dfa, plot.type = "std.model.resids.ytT")
ggplot2::autoplot(best_fit_dfa, plot.type = "qqplot.std.model.resids.ytt1")
formatted_matrices_dfa= results_DFA(best_fit_dfa)
formatted_matrices_dfa
signe_trend<-c()
for(i in 1:ncol(unlist(formatted_matrices_dfa$Z.conf$Z))){
if(
length(formatted_matrices_dfa$Z.conf$Z[,i][formatted_matrices_dfa$Z.conf$Z[,i]>0]) <
length(formatted_matrices_dfa$Z.conf$Z[,i][formatted_matrices_dfa$Z.conf$Z[,i]<0]))
{signe_trend[i]<- -1}
else{signe_trend[i]<- 1}
}
graph_Z(formatted_matrices_dfa$Z.conf, sign_trends = signe_trend)
graph_trends(trends = formatted_matrices_dfa$trends, sort(unique(silver_arr$das_year)), sign_trends = signe_trend)
source("../../utilities/load_library.R")
knitr::opts_chunk$set(echo = TRUE,warning=FALSE,message=FALSE,
fig.width=14.9/2.54,
dpi=300,
fig.height=10/2.54)
load_library("RPostgres")
load_library("dplyr")
load_library("tidyr")
load_library("readxl")
load_library("yaml")
load_library("flextable")
load_library("ggplot2")
cred=read_yaml("../../../credentials.yml")
con_wgeel = dbConnect(Postgres(), dbname=cred$dbname,host=cred$host,port=cred$port,user=cred$user, password=cred$password)
query='SELECT
das_id,
das_value,
das_effort,
das_year,
das_comment,
ser_id,
cou_order,
ser_nameshort,
ser_area_division,
ser_qal_id,
ser_hty_code,
ser_emu_nameshort,
ser_uni_code,
ser_cou_code,
ser_comment,
sam_samplingtype,
ser_sam_id, ser_distanceseakm, ser_method, ser_sam_gear, ser_restocking,
das_qal_id,
das_last_update,
f_subarea,
lfs_code,
lfs_name
from datawg.t_dataseries_das
join datawg.t_series_ser on das_ser_id=ser_id
left join ref.tr_samplingtype_sam on ser_sam_id=sam_id
left join ref.tr_lifestage_lfs on ser_lfs_code=lfs_code
left join ref.tr_faoareas on ser_area_division=f_division
left join ref.tr_country_cou on cou_code=ser_cou_code
where ser_typ_id in (2,3) and das_value is not null and  (ser_qal_id IS NULL OR ser_qal_id IN (0,1,2,4)) and (das_qal_id IS NULL OR das_qal_id IN (1,2,4))'
mydata = dbGetQuery(con_wgeel,query) # Get yellow and silver eel time series from WGEEL database
dbDisconnect(con_wgeel) #disconnect from WGEEL database
d.ecoregion = read.csv2("data/points_with_ecoregions_forRob.csv") %>% #Load data on ecoregion of dataseries
rename(ecoregion = new_Ecoreg)
####################
### Get data in right format
data <- mydata %>%
filter(lfs_code == "S") %>% #Filter data down to silver eel timeseries
arrange(ser_nameshort, das_year) %>% # Sort data for better overview
left_join(d.ecoregion %>% select(ser_id, ecoregion, distance_to_ecoregion)) # Add ecoregion info
####################
### Assign type of effort data available and any relevant notes
d.effort = data %>%
select(ser_nameshort) %>%
unique() %>%
mutate(effort = case_when(
ser_nameshort %in% c("BreS",  "FreS",  "KilS",   "SeNS",   "SouS",  "StrS",  "DaugS",  "LilS" ) ~ "provided",
ser_nameshort %in% c("BI1S",  "BI4S", "BRWS",  "DoijS", "HVWS",  "IjsS", "KotkS", "LoiS", "MinS",  "MonS",  "NiWS", "NkaS",  "NZKS", "OriS",  "PanS",  "PobeS", "PogoS", "PolsS", "SosS",  "TibeS", "ZMaS", "NSIS" ) ~ "index",
ser_nameshort %in% c("BaBS",  "BidS",  "BurS",  "EamtS", "FowS",  "GiBS",  "ImsaS", "KavlS", "LevS",  "NalS",  "NorwS", "ShiS",  "VaakS",  "WepeS") ~ "constant",
ser_nameshort %in% c("RibS", "VilS", "WarS") ~ "model estimate",
ser_nameshort %in% c("AlauS", "AlCS",  "CurlS", "KertS", "KreS",  "LakS",  "RieS",  "RubS",  "SiesS", "ZeiS" ) ~ "unknown"
),
notes = case_when(
ser_nameshort %in% c("AlauS",  "CurlS",  "KertS",  "KreS", "LakS",  "RieS",  "RubS",  "SiesS",  "ZeiS") ~ "Next year double check for available effort data on all similar Lithuanian series, and check if only silver eel are reported",
ser_nameshort %in% c("AlCS") ~ "A mean of a subsample of commercial catches, no effort known",
ser_nameshort %in% c("NorwS",  "WepeS") ~ "Recent years reported as 0, but actually no information available"
)
)
if(any(is.na(d.effort$effort))){
stop("qualitative effort information from the following series is missing: ",
paste(d.effort$ser_nameshort[which(is.na(d.effort$effort))], collapse = ", "),
". Manually insert this into the d.effort dataframe before proceeding.")
}
### Filter data down to relevant silver eel series
# Filter data according to time series length, and the availability of effort data
# If no data on effort is known, then the series cannot be used to analyse trends in abundance/CPUE.
# Sometimes, no effort data is given because all silver eel passing through a river are sampled. This data is kept here,
# perhaps advise in next year's data call to set such effort equal to 1 in the das_effort column
min.length = 10 #minimum time-series length, delete series with fewer number of years
#Overview table to be used in the subgroup text to show which series were kept and which were discarded
t.filterchoice <- data %>%
count(ser_nameshort, ser_method) %>% #filter data down to series name and method, while counting time series length
left_join(d.effort %>% select(ser_nameshort, effort, notes)) %>% #Add information on effort type/availability
mutate(filtered = case_when(
n < min.length ~ "Dropped", # Set a variable specifying if the column should be filtered out based on time-series length
effort == "unknown" ~ "Dropped", # Drop series with unknown effort
ser_nameshort %in% c("NorwS", "WepeS") ~ "Dropped", #These two series have had trouble reporting in recent years, data for those years not reliable, drop until issue is resolved.
TRUE ~ "Kept"
),
reason.dropped = case_when(
n < min.length ~ paste("Number of years fewer than",min.length, sep = " "),
effort == "unknown" ~ "No effort given",
ser_nameshort %in% c("NorwS", "WepeS") ~ "Inconsistencies in data",
TRUE ~ ""
)
)
### NOTE: LevS reports no effort (assumed constant effort), but lists multiple years with deviations in sampling times, and thus different effort. Choose what to do with those.
# Apply the filter to the data, calculate CPUE, process data to output format
d.cpue <- data %>%
left_join(t.filterchoice %>% select(ser_nameshort, effort, filtered)) %>% #add filter choice
filter(filtered != "Dropped") %>% #filter out selected series
mutate(cpue = case_when( # Calculate CPUE based on data type
effort == "index" ~ das_value,
effort == "model estimate" ~ das_value,
effort == "constant" ~ das_value,
effort == "provided" ~ das_value/das_effort
)
) %>% #calculate cpue if effort data is given, otherwise assume that das_value is already CPUE
select(das_id, das_year, cpue, das_value, das_effort, ser_id, ser_nameshort, ser_hty_code, ser_emu_nameshort, ser_cou_code, ser_distanceseakm, ser_restocking, ecoregion, distance_to_ecoregion, das_qal_id, ser_qal_id)
dbDisconnect(con_wgeel)
d.cpue<-d.cpue%>%filter(das_year>1979)
## Arrange the data for the dfa
silver_arr <-d.cpue %>%
ungroup %>% #removed the ser_id grouping
select(ser_nameshort, cpue,das_year) %>%
arrange(das_year)%>%
pivot_wider(names_from=ser_nameshort,values_from=cpue)
silver_arr
