---
title: "JAGS SEASONALITY OF LANDINGS"
author: "Hilaire Drouineau"
date: "23 janvier 2020"
output: 
  rmarkdown::html_document:
     keep_md: yes
     toc: yes
    toc_depth: 3
    toc_float: yes
  rmarkdown::md_document:
     toc: yes
  rmarkdown::word_document:
    toc: true
---
```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=10, fig.height=10,warning=FALSE)
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
wdsource <-"~/Documents/Bordeaux/migrateurs/WGEEL/wkeelmigration/source/"
load("res_landings.Rdata")
source("function_for_model.R")
library(dplyr)
library(tidyverse)
library(tidyr)
library(ggthemes)
library(runjags)
library(coda)
library(ggplot2)
library(doParallel)
library(RColorBrewer)
library(kableExtra)
source("closure_vs_landings.R")
library(sf)
library(RPostgreSQL)
con<-dbConnect(PostgreSQL(),host="localhost",dbname="wgeel_old",user="hilaire")
emu <- st_read(con,query="select * from carto.emu")
cou <- st_read("/mnt/SIG/01-REFERENTIELS/LIMITES_ADMINISTRATIVES_monde/european_countries_WGS84.shp")
cou <- st_transform(cou, crs=4326)
dbDisconnect(con)

pal= brewer.pal(7,"Set2")
cols <- c("1" = pal[1], "2"= pal[2],"3" = pal[3], "4" = pal[4],  "5" = pal[5], "6"=pal[6], "7"=pal[7])

```

# Introduction
We start by loading the rdata provided by CÃ©dric who has imported and edited all the xlsx files. He also provides a very good overview of the content [here](landings_seasonality.md). Based on this job, we will try to carry out a similar analysis as for [seasonality](jags_modelling.md). More specifically, we can use the same Bayesian model to make a clustering of time series. For each stage, we will build a data set that gives for each season, and each EMU (and perhaps habitat), the proportion of catches per month.

For convenience, we rename the data.frame with names consistent with the seasonality data.set

```{r}
res <- res %>%
  rename(das_month=month, das_value=value, das_year=year)
```

# Glass Eel
First, let's select data corresponding to glass eel stage.

```{r}
glass_eel <- subset(res, res$lfs_code=="G")

# we start by removing rows with only zero
all_zero <- glass_eel %>%	group_by(emu_nameshort,lfs_code,hty_code,das_year) %>%
		summarize(S=sum(das_value)) %>% 
    filter(S==0)

glass_eel <- glass_eel %>% 
	  anti_join(all_zero)



#For glass eel, we aggregate data per habitat
glass_eel <- glass_eel %>%
  select(das_year, das_month, das_value, emu_nameshort, cou_code) %>%
  group_by(das_year, das_month, emu_nameshort, cou_code) %>%
  summarise(das_value=sum(das_value))
```

Similarly to seasonality, we will build season. For glass eels, seasons are rather consistent in whole Europe, so we use the same definition as in seasonality: Here, we split in october (starts of catches in Spain) and a season y will correspond to ostober - december y-1 and january to september y.

```{r}
glass_eel$season <- ifelse(glass_eel$das_month>9,
                             glass_eel$das_year+1,
                             glass_eel$das_year)
glass_eel$month_in_season <- as.factor(ifelse(glass_eel$das_month>9,
                                      glass_eel$das_month-9,
                                      glass_eel$das_month+3)) #1 stands for nov,

#we remove data from season 2020
glass_eel <- glass_eel %>%
  filter(season < 2020)

```

## Data selection
Now we should carry out data selection, more specifically, we want to eliminate rows with two many missing data, too much zero and to check whether there are no duplicates (though Cedric already did it)

```{r, warning=FALSE}
kept_seasons <- lapply(unique(glass_eel$emu_nameshort), function(s){
  sub_glass <- subset(glass_eel, glass_eel$emu_nameshort==s)
  good_coverage_wave(sub_glass, "G")
})
```

Finally, here are the series kept given previous criterion.

```{r}
names(kept_seasons) <- unique(glass_eel$emu_nameshort)
kept_seasons[!sapply(kept_seasons,is.null)]
```

## Data preparation
We carry out the same procedure as for seasonality. 

```{r}
glasseel_subset <- subset(glass_eel, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, glass_eel$season, glass_eel$emu_nameshort))


glasseel_wide <- pivot_wider(data=glasseel_subset[, c("emu_nameshort",
                                                     "cou_code",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(glasseel_wide)[-(1:3)] <- paste("m",
                                       names(glasseel_wide)[-(1:3)],
                                       sep="")

###we count the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(glasseel_wide$emu_nameshort,
                        glasseel_wide$season,
                  zero=rowSums(glasseel_wide[, -(1:3)] == 0 |
                                 is.na(glasseel_wide[, -(1:3)])),
           tot=rowSums(glasseel_wide[, -(1:3)], na.rm=TRUE))

glasseel_wide <- glasseel_wide[data_poor$zero < 10 & data_poor$tot>30, ]

table_datapoor(data_poor %>% filter(zero > 9 | tot<50)) #we remove years where we have less than 2 months)
```

It leads to a dataset with `r nrow(glasseel_wide)` rows. 

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months / closed months, and we compute proportions per month for each year.

```{r}
glasseel_wide <- glasseel_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
glasseel_wide[, -(1:3)] <- glasseel_wide[, -(1:3)] + 1e-3
total_catch_year <- rowSums(glasseel_wide[, paste("m", 1:12, sep="")])
glasseel_wide <- glasseel_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.


```{r}
glasseel_wide$period <- ifelse(glasseel_wide$season>2009,
                                  2,
                                  1)

kable(table(glasseel_wide$period,
       glasseel_wide$emu_nameshort),
      caption="number of seasons per period",
      row.names=TRUE)
```

The situation is well balanced between the two periods.


## Running the model
```{r}
group <- as.integer(interaction(glasseel_wide$emu_nameshort,
                                            glasseel_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(glasseel_wide[, paste("m", 1:12, sep="")])
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
cl <- makeCluster(3, 'FORK')
comparison <- parSapply(cl, 2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         adapted <- FALSE
         while (!adapted){
           tryCatch({
             runjags.options(adapt.incomplete="error")
             res <- run.jags("jags_model.txt", monitor= c("deviance",
                                                          "alpha_group",
                                                          "cluster"),
                        summarise=FALSE, adapt=40000, method="parallel",
                        sample=2000,burnin=100000,n.chains=1,
                        inits=generate_init(nbclus, mydata)[[1]],
                        data=mydata)
                        adapted <- TRUE
                        res_mat <- as.matrix(as.mcmc.list(res))
                        silhouette <- median(compute_silhouette(res_mat))
                        nbused <- apply(res_mat, 1, function(iter){
                          length(table(iter[grep("cluster",
                                                 names(iter))]))
                        })
                        dic <- mean(res_mat[,1])+0.5*var(res_mat[,1])
                        stats <- c(dic,silhouette,mean(nbused))
                  }, error=function(e) {
                    print(paste("not adapted, restarting nbclus",nbclus))
                    }
                  )
         }
         stats
      })
stopCluster(cl)
best_glasseel_landings <- data.frame(nbclus=2:(ncol(comparison)+1),
                                              dic=comparison[1, ],
                                              silhouette=comparison[2, ],
                                     used=comparison[3,])
save(best_glasseel_landings, file="glasseel_landings_jags.rdata")



```

```{R}
load("best_glasseel_landings")
best_glasseel_landings
```


Given that the number of used clusters do not increase much after 4 and that the silhouette tends to decrease, we use 4 clusters.


```{r, eval=FALSE}
nbclus <- 4
mydata <-build_data(4)


adapted <- FALSE
while (!adapted){
   tryCatch({
      runjags.options(adapt.incomplete="error")
      myfit_glasseel_landings <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=50000, method="parallel",
                      sample=10000,burnin=200000,n.chains=1, thin=5,
                      inits=generate_init(nbclus, mydata)[[1]], data=mydata)
      adapted <- TRUE
    }, error=function(e) {
       print(paste("not adapted, restarting nbclus",nbclus))
    })
}

save(myfit_glasseel_landings, best_glasseel_landings,
     file="glasseel_landings_jags.rdata")
```


## Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("glasseel_landings_jags.rdata")
nbclus <- 4
mydata <-build_data(4)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res, add.mutate=FALSE))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}

pat <-get_pattern_month(myfit_glasseel_landings)
#we number cluster in chronological orders from november to october
clus_order=c("3","1","4","2")
pat$cluster <- factor(match(pat$cluster,clus_order),
                      levels=as.character(1:7))
ggplot(pat,aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  scale_fill_manual(values=cols)+facet_wrap(.~cluster, ncol=1) +
  theme_igray()
```

We compute some statistics to characterize the clusters.
```{r}
table_characteristics(myfit_glasseel_landings, 4,clus_order)
```

Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.

Clusters 1 starts in autum and last still january. Cluster 2 is shifter one month later and lasts longer. Cluster 3 corresponds to catches in march/may. Cluster 4 is very flat and is not really attributed.

We can also look at the belonging of the different groups.

```{r}
groups <- interaction(glasseel_wide$emu_nameshort,
                                            glasseel_wide$period,
                                            drop=TRUE)
group_name <- levels(groups)

get_pattern_month <- function(res,mydata){
  
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res,add.mutate=FALSE))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", paste("clus",seq_len(nbclus),sep=""))
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_glasseel_landings)
col_toreorder=grep("clus[0-9]",names(myclassif))
names(myclassif)[col_toreorder]=paste("clus",
                                      match(paste("clus",1:nbclus,sep=""),
                                      paste("clus",clus_order,sep="")),
                                      sep="")
myclassif[,col_toreorder] <- myclassif%>%
  select(col_toreorder)%>%select(sort(names(.)))
myclassif$cluster <- factor(match(myclassif$cluster,clus_order),
                            levels=as.character(1:7))

table_classif(myclassif)
```

The spatial pattern is obvious in the results. Interestingly, we saw an EMU that change cluster between period and this seem to correspond to management measures that have effectively shorten the fishing season.

```{r}
myclassif_p1 <- subset(myclassif, myclassif$period == 1)
myclassif_p2 <- subset(myclassif, myclassif$period == 2)
emu$cluster1 <- factor(myclassif_p1$cluster[match(emu$name_short,
                                                  substr(myclassif_p1$ser,1,nchar(as.character(myclassif_p1$ser))))], levels=1:7)

emu$cluster2 <- factor(myclassif_p2$cluster[match(emu$name_short,
                                                substr(myclassif_p2$ser,1,nchar(as.character(myclassif_p2$ser))))],
                       levels=1:7)
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster1)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65) 
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster2)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65)  

```

## Exporting pattern per group
```{r}
tmp <- as.matrix(as.mcmc.list(myfit_glasseel_landings))
name_col = colnames(tmp)

pattern_GE_landings=do.call("rbind.data.frame",
                            lapply(seq_len(length(levels(groups))), function(g)
                                   median_pattern_group(g, group_name,tmp, "G","landings", hty_code="T")))
save(pattern_GE_landings,file="pattern_G_landings.rdata")
```

## Similarity between and after 2010
```{r}
#which groups have data in both periods
occ=table(unique(glasseel_wide[,c("emu_nameshort", "period")])[,1])
tocompare=names(occ)[which(occ>1)]

simi=sapply(tocompare, function(s){
  g=grep(s,group_name)
  esp1=tmp[,grep(paste("alpha_group\\[",g[1],",",sep=""),name_col)]
  esp2=tmp[,grep(paste("alpha_group\\[",g[2],",",sep=""),name_col)]
  quantile(apply(cbind(esp1,esp2),
                 1,
                 function(x) sum(pmin(x[1:12],x[13:24]))),
           probs=c(0.025,.5,.975))
})

similarity=data.frame(emu=tocompare,t(simi))

table_similarity(similarity)
```


##Potential effect of EMP and EU closures
```{r}
ncar=nchar(group_name)
period=as.integer(substr(as.character(group_name),ncar,ncar))
emus=substr(group_name,1,ncar-2)



#######EMP
#For glass eels, we summed catches over hty, therefore here, we aggregate closures
#taking the most restrictive if there are differences among habitats
list_period1=data.frame(emu_nameshort=emus[period==1])
list_period1$group=group_name[period==1]
list_period1$id_g=match(list_period1$group,group_name)

#we check that we have ladings data at least two years before the first EMP closures
list_period1$estimable=sapply(list_period1$emu_nameshort, function(s) {
  length(which(charac_EMP_closures$emu_nameshort==s 
               & grepl("G",charac_EMP_closures$lfs_code) 
               & charac_EMP_closures$hty_code != "F"))>0})

list_period1$estimable=list_period1$estimable &
(sapply(list_period1$id_g,function(e) min(glasseel_wide$season[group==e]))+2 <
sapply(list_period1$emu_nameshort,function(e) min(charac_EMP_closures$year[charac_EMP_closures$emu_nameshort==e &
                                                           grepl("G",charac_EMP_closures$lfs_code) &
                                                    charac_EMP_closures$hty_code !="F"])))

list_period1$lossq2.5=NA
list_period1$lossq50=NA
list_period1$lossq97.5=NA

res_closures=mapply(function(s,g) {
  emu_closures <- EMP_closures %>%
    filter(emu_nameshort==s & grepl("G",lfs_code) & hty_code !="F") %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period1$emu_nameshort[list_period1$estimable]),list_period1$id_g[list_period1$estimable])

list_period1[list_period1$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period1[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EMP closure",
      digits=2)







#######EU
#For glass eels, we summed catches over hty, therefore here, we aggregate closures
#taking the most restrictive if there are differences among habitats
list_period2=data.frame(emu_nameshort=emus[period==2])
list_period2$group=group_name[period==2]
list_period2$id_g=match(list_period2$group,group_name)

#we check that we have ladings data at least two years before the first EU closures
list_period2$estimable=sapply(list_period2$emu_nameshort, function(s) {
  length(which(charac_EU_closures$emu_nameshort==s 
               & grepl("G",charac_EU_closures$lfs_code) 
               & charac_EU_closures$hty_code != "F"))>0})

list_period2$estimable=list_period2$estimable &
(sapply(list_period2$id_g,function(e) min(glasseel_wide$season[group==e]))+2 <
sapply(list_period2$emu_nameshort,function(e) min(charac_EU_closures$year[charac_EU_closures$emu_nameshort==e &
                                                           grepl("G",charac_EU_closures$lfs_code) &
                                                    charac_EU_closures$hty_code !="F"])))

list_period2$lossq2.5=NA
list_period2$lossq50=NA
list_period2$lossq97.5=NA

res_closures=mapply(function(s,g) {
  emu_closures <- EU_closures %>%
    filter(emu_nameshort==s & grepl("G",lfs_code) & hty_code !="F") %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period2$emu_nameshort[list_period2$estimable]),list_period2$id_g[list_period2$estimable])

list_period2[list_period2$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period2[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EU closure",
      digits=2)


list_period2$type="EU closure"
list_period1$type="EMP closure"
list_period=rbind.data.frame(list_period1,list_period2)
list_period$stage="G"
save(list_period,file="loss_glass_eel.rdata")


####scenario per cluster
starts_closure=8:12
clus=1:nbclus
experiments=expand.grid(clus,starts_closure)
effects=t(mapply(function(c,s){
  months_closed=(s:(s+2))
  months_closed=ifelse(months_closed>12,months_closed-12,months_closed)
  pattern=tmp[,grep(paste("esp\\[",c,",",sep=""),colnames(tmp))]
  effect=rowSums(pattern[,months_closed])
  quantile(effect,probs=c(0.025,.5,.975))
},experiments[,1],experiments[,2]))
effects_scenario=data.frame(cluster=match(experiments[,1],clus_order),
                            starting_month_EU_closure=experiments[,2],
                            loss_median=effects[,2],
                            loss_2.5=effects[,1],
                            loss_97.5=effects[,3])
effects_scenario=effects_scenario[order(effects_scenario$cluster,
                                        effects_scenario$starting_month_EU_closure),]


kable(effects_scenario,row.names=FALSE,col.names=c("cluster",
                                   "speculative 1st month of EU closure",
                                   "median loss of catch",
                                   "q2.5",
                                   "q97.5"), digits=2,
      caption="potential effect that an EU closure would have depending on cluster and starting month")

```


# Yellow
First, let's select data corresponding to yellow stage.

```{r}
yellow_eel <- subset(res, res$lfs_code=="Y")

# we start by removing rows with only zero
all_zero <- yellow_eel %>%	group_by(emu_nameshort,lfs_code,hty_code,das_year) %>%
		summarize(S=sum(das_value)) %>% 
    filter(S==0)

yellow_eel <- yellow_eel %>% 
	  anti_join(all_zero)

table(yellow_eel$hty_code)

#We have many data, so we remove "FC" and "FTC" which are weirds mixes
yellow_eel <- yellow_eel %>%
  filter(!hty_code %in% c("FTC", "FC"))

#in this analysis, the unit will correspond to EMU / habitat so we create 
#corresponding column
yellow_eel$emu <- yellow_eel$emu_nameshort
yellow_eel$emu_nameshort <- paste(yellow_eel$emu_nameshort,
                                   yellow_eel$hty_code, sep="_")

#There are some duplicates for IE_West_F that should be summed up according to
#Russel
summed_up_IE <-yellow_eel %>%
  filter(yellow_eel$emu_nameshort=="IE_West_F") %>%
  group_by(das_year,das_month) %>%
  summarize(das_value=sum(das_value))

yellow_eel <- yellow_eel %>% 
  distinct(das_year,das_month,emu_nameshort, .keep_all = TRUE)

yellow_eel[yellow_eel$emu_nameshort=="IE_West_F",
          c("das_year","das_month","das_value") ] <- summed_up_IE
  
```

Similarly to seasonality, we will build season. We reuse the procedure made for silver eel and yellow eel seasonality, i.e. defining seasons per emu, with the season starting at the month with minimum landings. The month with lowest catch fmin define the beggining of the season (month_in_season=1) and season y stands for the 12 months from fmin y (e.g., if lowest migration is in december, season ranges from december to november, and season y denotes season from december y to november y+1).

```{r}
#creating season
yelloweel <- do.call("rbind.data.frame",
                     lapply(unique(yellow_eel$emu_nameshort),
                            function(s)
                              season_creation(yellow_eel[yellow_eel$emu_nameshort==s,])))
months_peak_per_series<- unique(yelloweel[,c("emu_nameshort","peak_month")])

#large variety in the month with peak of catches among EMU / habitat
kable(table(months_peak_per_series$peak_month),
      caption="number of EMUs that peak in a month",
      col.names=c("month","number of EMUs"))

#we remove data from season 2020
yelloweel <- yelloweel %>%
  filter(season < 2020)

```


##Coastal/marine waters
### Data selection
Now we should carry out data selection, more specifically, we want to eliminate rows with two many missing data, too much zero and to check whether there are no duplicates (though Cedric already did it). We mixed coastal and marine habitats since there are only one EMU with landings in marine habitat

```{r, warning=FALSE}
yelloweel_coatal <- subset(yelloweel, yelloweel$hty_code %in% c("C", "MO"))
kept_seasons <- lapply(unique(yelloweel_coatal$emu_nameshort), function(s){
  sub_yellow <- subset(yelloweel_coatal, yelloweel_coatal$emu_nameshort==s)
  kept <- good_coverage_wave(sub_yellow)
  #we remove season in which we have less than 50 kg of landings
  if(!is.null(kept))
    kept <- kept[sapply(kept,function(k)
      sum(sub_yellow$das_value[sub_yellow$season==k],na.rm=TRUE)>50)]
  if (length(kept) == 0) kept <- NULL
  kept
})
```

Finally, here are the series kept given previous criterion.

```{r}
names(kept_seasons) <- unique(yelloweel_coatal$emu_nameshort)
kept_seasons[!sapply(kept_seasons,is.null)]
```

### Data preparation
We carry out the same procedure as for seasonality. 

```{r}
yelloweel_coastal_subset <- subset(yelloweel_coatal, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, yelloweel_coatal$season, yelloweel_coatal$emu_nameshort))


yelloweel_coastal_wide <- pivot_wider(data=yelloweel_coastal_subset[, c("emu_nameshort",
                                                     "cou_code",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(yelloweel_coastal_wide)[-(1:3)] <- paste("m",
                                       names(yelloweel_coastal_wide)[-(1:3)],
                                       sep="")

###we count the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(yelloweel_coastal_wide$emu_nameshort,
                        yelloweel_coastal_wide$season,
                  zero=rowSums(yelloweel_coastal_wide[, -(1:3)] == 0 |
                                 is.na(yelloweel_coastal_wide[, -(1:3)])),
           tot=rowSums(yelloweel_coastal_wide[, -(1:3)], na.rm=TRUE))
yelloweel_coastal_wide <- yelloweel_coastal_wide[data_poor$zero < 10, ]

table_datapoor(data_poor %>% filter(zero > 9 | tot<50)) #we remove years where we have less than 2 months)
```

It leads to a dataset with `r nrow(yelloweel_coastal_wide)` rows. 

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months / closed months, and we compute proportions per month for each year.

```{r}
yelloweel_coastal_wide <- yelloweel_coastal_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
yelloweel_coastal_wide[, -(1:3)] <- yelloweel_coastal_wide[, -(1:3)] + 1e-3
total_catch_year <- rowSums(yelloweel_coastal_wide[, paste("m", 1:12, sep="")])
yelloweel_coastal_wide <- yelloweel_coastal_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
yelloweel_coastal_wide$period <- ifelse(yelloweel_coastal_wide$season>2009,
                                  2,
                                  1)

kable(table(yelloweel_coastal_wide$period,
       yelloweel_coastal_wide$emu_nameshort),
      row.names=TRUE,
      caption="number of seasons per EMU and period")
```

The situation is not well balanced. Most EMU which have data in periods 1 don't have data in period 2 and conversely.


### Running the model
```{r}
group <- as.integer(interaction(yelloweel_coastal_wide$emu_nameshort,
                                            yelloweel_coastal_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(yelloweel_coastal_wide[, paste("m", 1:12, sep="")])
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
cl <- makeCluster(3, 'FORK')
comparison <- parSapply(cl,2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         adapted <- FALSE
         while (!adapted){
           tryCatch({
             runjags.options(adapt.incomplete="error")
             res <- run.jags("jags_model.txt", monitor= c("deviance",
                                                          "alpha_group",
                                                          "cluster"),
                        summarise=FALSE, adapt=40000, method="parallel",
                        sample=2000,burnin=100000,n.chains=1,
                        inits=generate_init(nbclus, mydata)[[1]],
                        data=mydata)
                        adapted <- TRUE
                        res_mat <- as.matrix(as.mcmc.list(res))
                        silhouette <- median(compute_silhouette(res_mat))
                        nbused <- apply(res_mat, 1, function(iter){
                          length(table(iter[grep("cluster",
                                                 names(iter))]))
                        })
                        dic <- mean(res_mat[,1])+0.5*var(res_mat[,1])
                        stats <- c(dic,silhouette,mean(nbused))
                  }, error=function(e) {
                    print(paste("not adapted, restarting nbclus",nbclus))
                    }
                  )
         }
         stats
      })
stopCluster(cl)
best_yelloweel_coastal_landings <- data.frame(nbclus=2:(ncol(comparison)+1),
                                              dic=comparison[1, ],
                                              silhouette=comparison[2, ],
                                              used=comparison[3, ])
save(best_yelloweel_coastal_landings, file="yelloweel_coastal_landings_jags.rdata")
```

```{R}
load("yelloweel_coastal_landings_jags.rdata")
best_yelloweel_coastal_landings
```

While 7 gives the best overall DIC, the DIC is rather flat and the number of cluster used does not evolve much so we stop at 3. 


```{r, eval=FALSE}
nbclus <- 3
mydata <-build_data(3)
adapted <- FALSE
while (!adapted){
   tryCatch({
      runjags.options(adapt.incomplete="error")
      myfit_yelloweel_coastal_landings <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=1, thin=5,
                      inits=generate_init(nbclus, mydata)[[1]], data=mydata)
      adapted <- TRUE
    }, error=function(e) {
       print(paste("not adapted, restarting nbclus",nbclus))
    })
}


save(myfit_yelloweel_coastal_landings, best_yelloweel_coastal_landings,
     file="yelloweel_coastal_landings_jags.rdata")
```

## Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("yelloweel_coastal_landings_jags.rdata")
nbclus <- 3
mydata <-build_data(3)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res, add.mutate=FALSE))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}

pat <-get_pattern_month(myfit_yelloweel_coastal_landings)
clus_order=c("2","3","1")
pat$cluster <- factor(match(pat$cluster,clus_order),
                         levels=as.character(1:7))
ggplot(pat,aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  scale_fill_manual(values=cols)+facet_wrap(.~cluster, ncol=1) +
  theme_igray()
```

Clusters 1 peaks summer. Clusters 2 peaks in winter, cluster 3 lasts from may to november.

We compute some statistics to characterize the clusters.

```{r}
table_characteristics(myfit_yelloweel_coastal_landings, 3,clus_order)

```

Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.


We can also look at the belonging of the different groups.
```{r}
groups <- interaction(yelloweel_coastal_wide$emu_nameshort,
                                            yelloweel_coastal_wide$period,
                                            drop=TRUE)
group_name <- levels(groups)
  
get_pattern_month <- function(res,mydata){
  

  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res,add.mutate=FALSE))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", paste("clus",seq_len(nbclus),sep=""))
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_yelloweel_coastal_landings)
col_toreorder=grep("clus[0-9]",names(myclassif))
names(myclassif)[col_toreorder]=paste("clus",
                                      match(paste("clus",1:nbclus,sep=""),
                                      paste("clus",clus_order,sep="")),
                                      sep="")
myclassif[,col_toreorder] <- myclassif%>%
  select(col_toreorder)%>%select(sort(names(.)))
myclassif$cluster <- factor(match(myclassif$cluster,clus_order),
                         levels=as.character(1:7))

table_classif(myclassif)
```

In fact, nearly all EMUs fall in cluster 3. Cluster 2 corresponds only to ES_Murc and cluster 1 to DE_Eide.

```{r}
myclassif_p1 <- subset(myclassif, myclassif$period == 1)
myclassif_p2 <- subset(myclassif, myclassif$period == 2)
emu$cluster1 <- factor(myclassif_p1$cluster[match(emu$name_short,
                                                  substr(myclassif_p1$ser,1,nchar(as.character(myclassif_p1$ser))-2))],
                       levels=1:7)
emu$cluster2 <- factor(myclassif_p2$cluster[match(emu$name_short,
                                                substr(myclassif_p2$ser,1,nchar(as.character(myclassif_p2$ser))-2))],
                       levels=1:7)
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster1)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65) 
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster2)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65)  

```

### Exporting pattern per group
```{r}
tmp <- as.matrix(as.mcmc.list(myfit_yelloweel_coastal_landings))
name_col = colnames(tmp)

pattern_Ycoast_landings=do.call("rbind.data.frame",
                                lapply(seq_len(length(levels(groups))), function(g)
                                   median_pattern_group(g, group_name,tmp, "Y","landings", hty_code="C")))


save(pattern_Ycoast_landings,file="pattern_Ycoast_landings.rdata")
```


### Similarity between and after 2010
```{r}
#which groups have data in both periods
occ=table(unique(yelloweel_coastal_wide[,c("emu_nameshort", "period")])[,1])
tocompare=names(occ)[which(occ>1)]

simi=sapply(tocompare, function(s){
  g=grep(s,group_name)
  esp1=tmp[,grep(paste("alpha_group\\[",g[1],",",sep=""),name_col)]
  esp2=tmp[,grep(paste("alpha_group\\[",g[2],",",sep=""),name_col)]
  quantile(apply(cbind(esp1,esp2),
                 1,
                 function(x) sum(pmin(x[1:12],x[13:24]))),
           probs=c(0.025,.5,.975))
})

similarity=data.frame(emu=tocompare,t(simi))

table_similarity(similarity)
```

### Potential effect of EMP and EU closures
```{r}
ncar=nchar(group_name)
period=as.integer(substr(as.character(group_name),ncar,ncar))
blocks=strsplit(group_name,"_")
emus=sapply(blocks,function(x)paste(x[1],x[2],sep="_"))
hty_code=sapply(blocks,function(x) substr(x[3],1,nchar(x[3])-2))



#######EMP
list_period1=data.frame(emu_nameshort=emus[period==1])
list_period1$group=group_name[period==1]
list_period1$id_g=match(list_period1$group,group_name)
list_period1$hty_code=hty_code[period==1]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period1$estimable=mapply(function(s,hty) {
  length(which(charac_EMP_closures$emu_nameshort==s 
               & grepl("Y",charac_EMP_closures$lfs_code) 
               & grepl(hty, charac_EMP_closures$hty_code)))>0},
  list_period1$emu_nameshort, list_period1$hty_code)

list_period1$estimable=list_period1$estimable &
(sapply(list_period1$id_g,function(e) min(yelloweel_coastal_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EMP_closures$year[charac_EMP_closures$emu_nameshort==e &
                                                           grepl("Y",charac_EMP_closures$lfs_code) &
                                                    grepl(hty,charac_EMP_closures$hty_code)]),
       list_period1$emu_nameshort, list_period1$hty_code))

list_period1$lossq2.5=NA
list_period1$lossq50=NA
list_period1$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EMP_closures %>%
    filter(emu_nameshort==s & grepl("Y",lfs_code) & grepl(hty, hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period1$emu_nameshort[list_period1$estimable]),
list_period1$id_g[list_period1$estimable],
list_period1$hty[list_period1$estimable])

list_period1[list_period1$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period1[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EMP closure",
      digits=2)




#######EU
list_period2=data.frame(emu_nameshort=emus[period==2])
list_period2$group=group_name[period==2]
list_period2$id_g=match(list_period2$group,group_name)
list_period2$hty_code=hty_code[period==2]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period2$estimable=mapply(function(s,hty) {
  length(which(charac_EU_closures$emu_nameshort==s 
               & grepl("Y",charac_EU_closures$lfs_code) 
               & grepl(hty, charac_EU_closures$hty_code)))>0},
  list_period2$emu_nameshort, list_period2$hty_code)

list_period2$estimable=list_period2$estimable &
(sapply(list_period2$id_g,function(e) min(yelloweel_coastal_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EU_closures$year[charac_EU_closures$emu_nameshort==e &
                                                           grepl("Y",charac_EU_closures$lfs_code) &
                                                    grepl(hty,charac_EU_closures$hty_code)]),
       list_period2$emu_nameshort, list_period2$hty_code))

list_period2$lossq2.5=NA
list_period2$lossq50=NA
list_period2$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EU_closures %>%
    filter(emu_nameshort==s & grepl("Y", lfs_code) & grepl(hty,hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period2$emu_nameshort[list_period2$estimable]),
list_period2$id_g[list_period2$estimable],
list_period2$hty_code[list_period2$estimable])

list_period2[list_period2$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period2[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EU closure",
      digits=2)

list_period2$type="EU closure"
list_period1$type="EMP closure"
list_period=rbind.data.frame(list_period1,list_period2)
list_period$stage="Y"
save(list_period,file="loss_yellowcoastal.rdata")


####scenario per cluster
starts_closure=8:12
clus=1:nbclus
experiments=expand.grid(clus,starts_closure)
effects=t(mapply(function(c,s){
  months_closed=(s:(s+2))
  months_closed=ifelse(months_closed>12,months_closed-12,months_closed)
  pattern=tmp[,grep(paste("esp\\[",c,",",sep=""),colnames(tmp))]
  effect=rowSums(pattern[,months_closed])
  quantile(effect,probs=c(0.025,.5,.975))
},experiments[,1],experiments[,2]))
effects_scenario=data.frame(cluster=match(experiments[,1],clus_order),
                            starting_month_EU_closure=experiments[,2],
                            loss_median=effects[,2],
                            loss_2.5=effects[,1],
                            loss_97.5=effects[,3])
effects_scenario=effects_scenario[order(effects_scenario$cluster,
                                        effects_scenario$starting_month_EU_closure),]


kable(effects_scenario,row.names=FALSE,col.names=c("cluster",
                                   "speculative 1st month of EU closure",
                                   "median loss of catch",
                                   "q2.5",
                                   "q97.5"), digits=2,
      caption="potential effect that an EU closure would have depending on cluster and starting month")



```


##transitional waters
### Data selection
Now we should carry out data selection, more specifically, we want to eliminate rows with two many missing data, too much zero and to check whether there are no duplicates (though Cedric already did it)

```{r, warning=FALSE}
yelloweel_transitional <- subset(yelloweel, yelloweel$hty_code =="T")
kept_seasons <- lapply(unique(yelloweel_transitional$emu_nameshort), function(s){
  sub_yellow <- subset(yelloweel_transitional, yelloweel_transitional$emu_nameshort==s)
  kept <- good_coverage_wave(sub_yellow)
  #we remove season in which we have less than 50 kg of landings
  if(!is.null(kept))
    kept <- kept[sapply(kept,function(k)
      sum(sub_yellow$das_value[sub_yellow$season==k],na.rm=TRUE)>50)]
  if (length(kept) == 0) kept <- NULL
  kept
})
```

Finally, here are the series kept given previous criterion.

```{r}
names(kept_seasons) <- unique(yelloweel_transitional$emu_nameshort)
kept_seasons[!sapply(kept_seasons,is.null)]
```


### Data preparation
We carry out the same procedure as for seasonality. 

```{r}
yelloweel_transitional_subset <- subset(yelloweel_transitional, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, yelloweel_transitional$season, yelloweel_transitional$emu_nameshort))


yelloweel_transitional_wide <- pivot_wider(data=yelloweel_transitional_subset[, c("emu_nameshort",
                                                     "cou_code",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(yelloweel_transitional_wide)[-(1:3)] <- paste("m",
                                       names(yelloweel_transitional_wide)[-(1:3)],
                                       sep="")

###we count the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(yelloweel_transitional_wide$emu_nameshort,
                        yelloweel_transitional_wide$season,
                  zero=rowSums(yelloweel_transitional_wide[, -(1:3)] == 0 |
                                 is.na(yelloweel_transitional_wide[, -(1:3)])),
           tot=rowSums(yelloweel_transitional_wide[, -(1:3)], na.rm=TRUE))
yelloweel_transitional_wide <- yelloweel_transitional_wide[data_poor$zero < 10 &
                                                             data_poor$tot>50, ]

table_datapoor(data_poor %>% filter(zero > 9 | tot<50)) #we remove years where we have less than 2 months)
```

It leads to a dataset with `r nrow(yelloweel_transitional_wide)` rows. 

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months / closed months, and we compute proportions per month for each year.

```{r}
yelloweel_transitional_wide <- yelloweel_transitional_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
yelloweel_transitional_wide[, -(1:3)] <- yelloweel_transitional_wide[, -(1:3)] + 1e-3
total_catch_year <- rowSums(yelloweel_transitional_wide[, paste("m", 1:12, sep="")])
yelloweel_transitional_wide <- yelloweel_transitional_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
yelloweel_transitional_wide$period <- ifelse(yelloweel_transitional_wide$season>2009,
                                  2,
                                  1)

table(yelloweel_transitional_wide$period,
       yelloweel_transitional_wide$emu_nameshort)
```

The situation is not well balanced. Most EMU which have data in periods 2.


### Running the model
```{r}
group <- as.integer(interaction(yelloweel_transitional_wide$emu_nameshort,
                                            yelloweel_transitional_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(yelloweel_transitional_wide[, paste("m", 1:12, sep="")])
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
cl <- makeCluster(3, 'FORK')
comparison <- parSapply(cl, 2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         adapted <- FALSE
         while (!adapted){
           tryCatch({
             runjags.options(adapt.incomplete="error")
             res <- run.jags("jags_model.txt", monitor= c("deviance",
                                                          "alpha_group",
                                                          "cluster"),
                        summarise=FALSE, adapt=40000, method="parallel",
                        sample=2000,burnin=100000,n.chains=1,
                        inits=generate_init(nbclus, mydata)[[1]],
                        data=mydata)
                        adapted <- TRUE
                        res_mat <- as.matrix(as.mcmc.list(res))
                        silhouette <- median(compute_silhouette(res_mat))
                        nbused <- apply(res_mat, 1, function(iter){
                          length(table(iter[grep("cluster",
                                                 names(iter))]))
                        })
                        dic <- mean(res_mat[,1])+0.5*var(res_mat[,1])
                        stats <- c(dic,silhouette,mean(nbused))
                  }, error=function(e) {
                    print(paste("not adapted, restarting nbclus",nbclus))
                    }
                  )
         }
         stats
      })
stopCluster(cl)
best_yelloweel_transitional_landings <- data.frame(nbclus=2:(ncol(comparison)+1),
                                              dic=comparison[1, ],
                                              silhouette=comparison[2, ],
                                              nbused=comparison[3,])
save(best_yelloweel_transitional_landings, file="yelloweel_transitional_landings_jags.rdata")
```

```{R}
load("yelloweel_transitional_landings_jags.rdata")
best_yelloweel_transitional_landings
```

4 appears to be a good solution: good silhouette and we have only 4 groups.

```{r, eval=FALSE}
nbclus <- 4
mydata <-build_data(4)
adapted <- FALSE
while (!adapted){
   tryCatch({
      runjags.options(adapt.incomplete="error")
      myfit_yelloweel_transitional_landings <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=1, thin=5,
                      inits=generate_init(nbclus, mydata)[[1]], data=mydata)
      adapted <- TRUE
    }, error=function(e) {
       print(paste("not adapted, restarting nbclus",nbclus))
    })
}


save(myfit_yelloweel_transitional_landings, best_yelloweel_transitional_landings,
     file="yelloweel_transitional_landings_jags.rdata")
```

## Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("yelloweel_transitional_landings_jags.rdata")
nbclus <- 4
mydata <-build_data(4)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res, add.mutate=FALSE))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}

pat <-get_pattern_month(myfit_yelloweel_transitional_landings)
clus_order=c("3", "2","4","1")
pat$cluster <- factor(match(pat$cluster,clus_order),
                      levels=as.character(1:7))
ggplot(pat,aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  scale_fill_manual(values=cols)+facet_wrap(.~cluster, ncol=1)+
  theme_igray()
```

There is much more diversity than in coastal waters. Some clusters peak in srping (3), summer (2), autumn (1) and one has two peaks (4). 

We compute some statistics to characterize the clusters.
```{r}
table_characteristics(myfit_yelloweel_transitional_landings, 4,clus_order)
```

Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.


We can also look at the belonging of the different groups.
```{r}
groups <- interaction(yelloweel_transitional_wide$emu_nameshort,
                                            yelloweel_transitional_wide$period,
                                            drop=TRUE)
group_name <- levels(groups)

get_pattern_month <- function(res,mydata){
  
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res,add.mutate=FALSE))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", paste("clus",seq_len(nbclus),sep=""))
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_yelloweel_transitional_landings)
col_toreorder=grep("clus[0-9]",names(myclassif))
names(myclassif)[col_toreorder]=paste("clus",
                                      match(paste("clus",1:nbclus,sep=""),
                                      paste("clus",clus_order,sep="")),
                                      sep="")
myclassif[,col_toreorder] <- myclassif%>%
  select(col_toreorder)%>%select(sort(names(.)))
myclassif$cluster <- factor(match(myclassif$cluster,clus_order),
                      levels=as.character(1:7))

table_classif(myclassif)
```

Cluster 4 stands only for Corsica. Some French EMUs have changed clusters after 2010 towards cluster 1 which has a small duration.

```{r}
myclassif_p1 <- subset(myclassif, myclassif$period == 1)
myclassif_p2 <- subset(myclassif, myclassif$period == 2)
emu$cluster1 <- factor(myclassif_p1$cluster[match(emu$name_short,
                                                  substr(myclassif_p1$ser,1,nchar(as.character(myclassif_p1$ser))-2))],
                       levels=1:7)
emu$cluster2 <- factor(myclassif_p2$cluster[match(emu$name_short,
                                                substr(myclassif_p2$ser,1,nchar(as.character(myclassif_p2$ser))-2))],
                       levels=1:7)
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster1)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65) 
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster2)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65)  

```

### Exporting pattern per group
```{r}
tmp <- as.matrix(as.mcmc.list(myfit_yelloweel_transitional_landings))
name_col = colnames(tmp)

pattern_Ytrans_landings=do.call("rbind.data.frame",
                                lapply(seq_len(length(levels(groups))), function(g)
                                   median_pattern_group(g, group_name,tmp, "Y","landings", hty_code="T")))
save(pattern_Ytrans_landings,file="pattern_Ytrans_landings.rdata")
```


### Similarity between and after 2010
```{r}
#which groups have data in both periods
occ=table(unique(yelloweel_transitional_wide[,c("emu_nameshort", "period")])[,1])
tocompare=names(occ)[which(occ>1)]

simi=sapply(tocompare, function(s){
  g=grep(s,group_name)
  esp1=tmp[,grep(paste("alpha_group\\[",g[1],",",sep=""),name_col)]
  esp2=tmp[,grep(paste("alpha_group\\[",g[2],",",sep=""),name_col)]
  quantile(apply(cbind(esp1,esp2),
                 1,
                 function(x) sum(pmin(x[1:12],x[13:24]))),
           probs=c(0.025,.5,.975))
})

similarity=data.frame(emu=tocompare,t(simi))

table_similarity(similarity)
```

### Potential effect of EMP and EU closures
```{r}
ncar=nchar(group_name)
period=as.integer(substr(as.character(group_name),ncar,ncar))
blocks=strsplit(group_name,"_")
emus=sapply(blocks,function(x)paste(x[1],x[2],sep="_"))
hty_code=sapply(blocks,function(x) substr(x[3],1,nchar(x[3])-2))



#######EMP
list_period1=data.frame(emu_nameshort=emus[period==1])
list_period1$group=group_name[period==1]
list_period1$id_g=match(list_period1$group,group_name)
list_period1$hty_code=hty_code[period==1]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period1$estimable=mapply(function(s,hty) {
  length(which(charac_EMP_closures$emu_nameshort==s 
               & grepl("Y",charac_EMP_closures$lfs_code) 
               & grepl(hty, charac_EMP_closures$hty_code)))>0},
  list_period1$emu_nameshort, list_period1$hty_code)

list_period1$estimable=list_period1$estimable &
(sapply(list_period1$id_g,function(e) min(yelloweel_transitional_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EMP_closures$year[charac_EMP_closures$emu_nameshort==e &
                                                           grepl("Y",charac_EMP_closures$lfs_code) &
                                                    grepl(hty,charac_EMP_closures$hty_code)]),
       list_period1$emu_nameshort, list_period1$hty_code))

list_period1$lossq2.5=NA
list_period1$lossq50=NA
list_period1$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EMP_closures %>%
    filter(emu_nameshort==s & grepl("Y",lfs_code) & grepl(hty, hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period1$emu_nameshort[list_period1$estimable]),
list_period1$id_g[list_period1$estimable],
list_period1$hty[list_period1$estimable])

list_period1[list_period1$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period1[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EMP closure",
      digits=2)







#######EU
list_period2=data.frame(emu_nameshort=emus[period==2])
list_period2$group=group_name[period==2]
list_period2$id_g=match(list_period2$group,group_name)
list_period2$hty_code=hty_code[period==2]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period2$estimable=mapply(function(s,hty) {
  length(which(charac_EU_closures$emu_nameshort==s 
               & grepl("Y",charac_EU_closures$lfs_code) 
               & grepl(hty, charac_EU_closures$hty_code)))>0},
  list_period2$emu_nameshort, list_period2$hty_code)

list_period2$estimable=list_period2$estimable &
(sapply(list_period2$id_g,function(e) min(yelloweel_transitional_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EU_closures$year[charac_EU_closures$emu_nameshort==e &
                                                           grepl("Y",charac_EU_closures$lfs_code) &
                                                    grepl(hty,charac_EU_closures$hty_code)]),
       list_period2$emu_nameshort, list_period2$hty_code))

list_period2$lossq2.5=NA
list_period2$lossq50=NA
list_period2$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EU_closures %>%
    filter(emu_nameshort==s & grepl("Y", lfs_code) & grepl(hty,hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period2$emu_nameshort[list_period2$estimable]),
list_period2$id_g[list_period2$estimable],
list_period2$hty_code[list_period2$estimable])

list_period2[list_period2$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period2[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EU closure",
      digits=2)

list_period2$type="EU closure"
list_period1$type="EMP closure"
list_period=rbind.data.frame(list_period1,list_period2)
list_period$stage="Y"
save(list_period,file="loss_yellowtransitional.rdata")




####scenario per cluster
starts_closure=8:12
clus=1:nbclus
experiments=expand.grid(clus,starts_closure)
effects=t(mapply(function(c,s){
  months_closed=(s:(s+2))
  months_closed=ifelse(months_closed>12,months_closed-12,months_closed)
  pattern=tmp[,grep(paste("esp\\[",c,",",sep=""),colnames(tmp))]
  effect=rowSums(pattern[,months_closed])
  quantile(effect,probs=c(0.025,.5,.975))
},experiments[,1],experiments[,2]))
effects_scenario=data.frame(cluster=match(experiments[,1],clus_order),
                            starting_month_EU_closure=experiments[,2],
                            loss_median=effects[,2],
                            loss_2.5=effects[,1],
                            loss_97.5=effects[,3])
effects_scenario=effects_scenario[order(effects_scenario$cluster,
                                        effects_scenario$starting_month_EU_closure),]


kable(effects_scenario,row.names=FALSE,col.names=c("cluster",
                                   "speculative 1st month of EU closure",
                                   "median loss of catch",
                                   "q2.5",
                                   "q97.5"), digits=2,
      caption="potential effect that an EU closure would have depending on cluster and starting month")

```



##freshwater waters
### Data selection
Now we should carry out data selection, more specifically, we want to eliminate rows with two many missing data, too much zero and to check whether there are no duplicates (though Cedric already did it)

```{r, warning=FALSE}
yelloweel_freshwater <- subset(yelloweel, yelloweel$hty_code =="F")
kept_seasons <- lapply(unique(yelloweel_freshwater$emu_nameshort), function(s){
  sub_yellow <- subset(yelloweel_freshwater, yelloweel_freshwater$emu_nameshort==s)
  kept <- good_coverage_wave(sub_yellow)
  #we remove season in which we have less than 50 kg of landings
  if(!is.null(kept))
    kept <- kept[sapply(kept,function(k)
      sum(sub_yellow$das_value[sub_yellow$season==k],na.rm=TRUE)>50)]
  if (length(kept) == 0) kept <- NULL
  kept
})
```

Finally, here are the series kept given previous criterion.

```{r}
names(kept_seasons) <- unique(yelloweel_freshwater$emu_nameshort)
kept_seasons[!sapply(kept_seasons,is.null)]
```


### Data preparation
We carry out the same procedure as for seasonality. 

```{r}
yelloweel_freshwater_subset <- subset(yelloweel_freshwater, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, yelloweel_freshwater$season, yelloweel_freshwater$emu_nameshort))


yelloweel_freshwater_wide <- pivot_wider(data=yelloweel_freshwater_subset[, c("emu_nameshort",
                                                     "cou_code",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(yelloweel_freshwater_wide)[-(1:3)] <- paste("m",
                                       names(yelloweel_freshwater_wide)[-(1:3)],
                                       sep="")

###we count the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(yelloweel_freshwater_wide$emu_nameshort,
                        yelloweel_freshwater_wide$season,
                  zero=rowSums(yelloweel_freshwater_wide[, -(1:3)] == 0 |
                                 is.na(yelloweel_freshwater_wide[, -(1:3)])),
           tot=rowSums(yelloweel_freshwater_wide[, -(1:3)], na.rm=TRUE))
yelloweel_freshwater_wide <- yelloweel_freshwater_wide[data_poor$zero < 10, ]

table_datapoor(data_poor %>% filter(zero > 9 | tot<50)) #we remove years where we have less than 2 months)

```


It leads to a dataset with `r nrow(yelloweel_freshwater_wide)` rows. 

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months / closed months, and we compute proportions per month for each year.

```{r}
yelloweel_freshwater_wide <- yelloweel_freshwater_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
yelloweel_freshwater_wide[, -(1:3)] <- yelloweel_freshwater_wide[, -(1:3)] + 1e-3
total_catch_year <- rowSums(yelloweel_freshwater_wide[, paste("m", 1:12, sep="")])
yelloweel_freshwater_wide <- yelloweel_freshwater_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```


The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
yelloweel_freshwater_wide$period <- ifelse(yelloweel_freshwater_wide$season>2009,
                                  2,
                                  1)

kable(table(yelloweel_freshwater_wide$period,
       yelloweel_freshwater_wide$emu_nameshort),
      row.names=TRUE,caption="number of seasons per EMU and period")
```

The situation is not well balanced. Most EMU which have data in periods 1 don't have data in period 2 and conversely.


### Running the model
```{r}
group <- as.integer(interaction(yelloweel_freshwater_wide$emu_nameshort,
                                            yelloweel_freshwater_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(yelloweel_freshwater_wide[, paste("m", 1:12, sep="")])
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
cl <- makeCluster(3, 'FORK')
comparison <- parSapply(cl, 2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         adapted <- FALSE
         while (!adapted){
           tryCatch({
             runjags.options(adapt.incomplete="error")
             res <- run.jags("jags_model.txt", monitor= c("deviance",
                                                          "alpha_group",
                                                          "cluster"),
                        summarise=FALSE, adapt=40000, method="parallel",
                        sample=2000,burnin=100000,n.chains=1,
                        inits=generate_init(nbclus, mydata)[[1]],
                        data=mydata)
                        adapted <- TRUE
                        res_mat <- as.matrix(as.mcmc.list(res))
                        silhouette <- median(compute_silhouette(res_mat))
                        nbused <- apply(res_mat, 1, function(iter){
                          length(table(iter[grep("cluster",
                                                 names(iter))]))
                        })
                        dic <- mean(res_mat[,1])+0.5*var(res_mat[,1])
                        stats <- c(dic,silhouette,mean(nbused))
                  }, error=function(e) {
                    print(paste("not adapted, restarting nbclus",nbclus))
                    }
                  )
         }
         stats
      })
stopCluster(cl)
best_yelloweel_freshwater_landings <- data.frame(nbclus=2:(ncol(comparison)+1),
                                              dic=comparison[1, ],
                                              silhouette=comparison[2, ],
                                              used=comparison[3,])
save(best_yelloweel_freshwater_landings, file="yelloweel_freshwater_landings_jags.rdata")
```

```{R}
load("yelloweel_freshwater_landings_jags.rdata")
best_yelloweel_freshwater_landings
```

Silhouette and DIC does not move much after 4, but only 3 clusters are used, therefore we keep 3.


```{r, eval=FALSE}
nbclus <- 3
mydata <-build_data(3)
adapted <- FALSE
while (!adapted){
   tryCatch({
      runjags.options(adapt.incomplete="error")
      myfit_yelloweel_freshwater_landings <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=1, thin=5,
                      inits=generate_init(nbclus, mydata)[[1]], data=mydata)
      adapted <- TRUE
    }, error=function(e) {
       print(paste("not adapted, restarting nbclus",nbclus))
    })
}


save(myfit_yelloweel_freshwater_landings, best_yelloweel_freshwater_landings,
     file="yelloweel_freshwater_landings_jags.rdata")
```

## Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("yelloweel_freshwater_landings_jags.rdata")
nbclus <- 3
mydata <-build_data(3)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res, add.mutate=FALSE))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}

pat <-get_pattern_month(myfit_yelloweel_freshwater_landings)
clus_order=c("1","3","2")
pat$cluster <- factor(match(pat$cluster, clus_order),
                       levels=as.character(1:7))
ggplot(pat,aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  scale_fill_manual(values=cols)+facet_wrap(.~cluster, ncol=1) +
  theme_igray()
```

Clusters 1 and 3 are bivariate, with 1 peaking in spring and autumn and 3 peaking in summer and autumn. Cluster 2 is widespread from may to november.

We compute some statistics to characterize the clusters.
```{r}
table_characteristics(myfit_yelloweel_freshwater_landings, 3, clus_order)
```

Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.


We can also look at the belonging of the different groups.
```{r}
groups <- interaction(yelloweel_freshwater_wide$emu_nameshort,
                                            yelloweel_freshwater_wide$period,
                                            drop=TRUE)
group_name <- levels(groups)

get_pattern_month <- function(res,mydata){
  
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res,add.mutate=FALSE))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", paste("clus",seq_len(nbclus),sep=""))
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_yelloweel_freshwater_landings)
col_toreorder=grep("clus[0-9]",names(myclassif))
names(myclassif)[col_toreorder]=paste("clus",
                                      match(paste("clus",1:nbclus,sep=""),
                                      paste("clus",clus_order,sep="")),
                                      sep="")
myclassif[,col_toreorder] <- myclassif%>%
  select(col_toreorder)%>%select(sort(names(.)))
myclassif$cluster <- factor(match(myclassif$cluster, clus_order),
                       levels=as.character(1:7))

table_classif(myclassif)
```

In fact, nearly all EMUs fall in cluster 2. Cluster 1 only corresponds to FR_Loir and cluster 3 to two bristish EMUs. There is no obvious spatial pattern nor period effect.

```{r}
myclassif_p1 <- subset(myclassif, myclassif$period == 1)
myclassif_p2 <- subset(myclassif, myclassif$period == 2)
emu$cluster1 <- factor(myclassif_p1$cluster[match(emu$name_short,
                                                  substr(myclassif_p1$ser,1,nchar(as.character(myclassif_p1$ser))-2))],
                       levels=1:7)
emu$cluster2 <- factor(myclassif_p2$cluster[match(emu$name_short,
                                                substr(myclassif_p2$ser,1,nchar(as.character(myclassif_p2$ser))-2))],
                       levels=1:7)
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster1)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65) 
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster2)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65)  

```

### Exporting pattern per group
```{r}
tmp <- as.matrix(as.mcmc.list(myfit_yelloweel_freshwater_landings))
name_col = colnames(tmp)

pattern_Yfresh_landings=do.call("rbind.data.frame",
                                lapply(seq_len(length(levels(groups))), function(g)
                                   median_pattern_group(g, group_name,tmp, "Y","landings", hty_code="F")))
save(pattern_Yfresh_landings,file="pattern_Yfresh_landings.rdata")
```

### Similarity between and after 2010
```{r}
#which groups have data in both periods
occ=table(unique(yelloweel_freshwater_wide[,c("emu_nameshort", "period")])[,1])
tocompare=names(occ)[which(occ>1)]

simi=sapply(tocompare, function(s){
  g=grep(s,group_name)
  esp1=tmp[,grep(paste("alpha_group\\[",g[1],",",sep=""),name_col)]
  esp2=tmp[,grep(paste("alpha_group\\[",g[2],",",sep=""),name_col)]
  quantile(apply(cbind(esp1,esp2),
                 1,
                 function(x) sum(pmin(x[1:12],x[13:24]))),
           probs=c(0.025,.5,.975))
})

similarity=data.frame(emu=tocompare,t(simi))

table_similarity(similarity)
```

### Potential effect of EMP and EU closures
```{r}
ncar=nchar(group_name)
period=as.integer(substr(as.character(group_name),ncar,ncar))
blocks=strsplit(group_name,"_")
emus=sapply(blocks,function(x)paste(x[1],x[2],sep="_"))
hty_code=sapply(blocks,function(x) substr(x[3],1,nchar(x[3])-2))



#######EMP
list_period1=data.frame(emu_nameshort=emus[period==1])
list_period1$group=group_name[period==1]
list_period1$id_g=match(list_period1$group,group_name)
list_period1$hty_code=hty_code[period==1]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period1$estimable=mapply(function(s,hty) {
  length(which(charac_EMP_closures$emu_nameshort==s 
               & grepl("Y",charac_EMP_closures$lfs_code) 
               & grepl(hty, charac_EMP_closures$hty_code)))>0},
  list_period1$emu_nameshort, list_period1$hty_code)

list_period1$estimable=list_period1$estimable &
(sapply(list_period1$id_g,function(e) min(yelloweel_freshwater_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EMP_closures$year[charac_EMP_closures$emu_nameshort==e &
                                                           grepl("Y",charac_EMP_closures$lfs_code) &
                                                    grepl(hty,charac_EMP_closures$hty_code)]),
       list_period1$emu_nameshort, list_period1$hty_code))

list_period1$lossq2.5=NA
list_period1$lossq50=NA
list_period1$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EMP_closures %>%
    filter(emu_nameshort==s & grepl("Y",lfs_code) & grepl(hty, hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period1$emu_nameshort[list_period1$estimable]),
list_period1$id_g[list_period1$estimable],
list_period1$hty[list_period1$estimable])

list_period1[list_period1$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period1[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EMP closure",
      digits=2)







#######EU
list_period2=data.frame(emu_nameshort=emus[period==2])
list_period2$group=group_name[period==2]
list_period2$id_g=match(list_period2$group,group_name)
list_period2$hty_code=hty_code[period==2]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period2$estimable=mapply(function(s,hty) {
  length(which(charac_EU_closures$emu_nameshort==s 
               & grepl("Y",charac_EU_closures$lfs_code) 
               & grepl(hty, charac_EU_closures$hty_code)))>0},
  list_period2$emu_nameshort, list_period2$hty_code)

list_period2$estimable=list_period2$estimable &
(sapply(list_period2$id_g,function(e) min(yelloweel_freshwater_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EU_closures$year[charac_EU_closures$emu_nameshort==e &
                                                           grepl("Y",charac_EU_closures$lfs_code) &
                                                    grepl(hty,charac_EU_closures$hty_code)]),
       list_period2$emu_nameshort, list_period2$hty_code))

list_period2$lossq2.5=NA
list_period2$lossq50=NA
list_period2$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EU_closures %>%
    filter(emu_nameshort==s & grepl("Y", lfs_code) & grepl(hty,hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period2$emu_nameshort[list_period2$estimable]),
list_period2$id_g[list_period2$estimable],
list_period2$hty_code[list_period2$estimable])

list_period2[list_period2$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period2[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EU closure",
      digits=2)

list_period2$type="EU closure"
list_period1$type="EMP closure"
list_period=rbind.data.frame(list_period1,list_period2)
list_period$stage="Y"
save(list_period,file="loss_yellowfresh.rdata")




####scenario per cluster
starts_closure=8:12
clus=1:nbclus
experiments=expand.grid(clus,starts_closure)
effects=t(mapply(function(c,s){
  months_closed=(s:(s+2))
  months_closed=ifelse(months_closed>12,months_closed-12,months_closed)
  pattern=tmp[,grep(paste("esp\\[",c,",",sep=""),colnames(tmp))]
  effect=rowSums(pattern[,months_closed])
  quantile(effect,probs=c(0.025,.5,.975))
},experiments[,1],experiments[,2]))
effects_scenario=data.frame(cluster=match(experiments[,1],clus_order),
                            starting_month_EU_closure=experiments[,2],
                            loss_median=effects[,2],
                            loss_2.5=effects[,1],
                            loss_97.5=effects[,3])
effects_scenario=effects_scenario[order(effects_scenario$cluster,
                                        effects_scenario$starting_month_EU_closure),]


kable(effects_scenario,row.names=FALSE,col.names=c("cluster",
                                   "speculative 1st month of EU closure",
                                   "median loss of catch",
                                   "q2.5",
                                   "q97.5"), digits=2,
      caption="potential effect that an EU closure would have depending on cluster and starting month")

```


##All habitats
### Data selection
Now we should carry out data selection, more specifically, we want to eliminate rows with two many missing data, too much zero and to check whether there are no duplicates (though Cedric already did it)

```{r, warning=FALSE}
yelloweel_allhab <- yelloweel
kept_seasons <- lapply(unique(yelloweel_allhab$emu_nameshort), function(s){
  sub_yellow <- subset(yelloweel_allhab, yelloweel_allhab$emu_nameshort==s)
  kept <- good_coverage_wave(sub_yellow)
  #we remove season in which we have less than 50 kg of landings
  if(!is.null(kept))
    kept <- kept[sapply(kept,function(k)
      sum(sub_yellow$das_value[sub_yellow$season==k],na.rm=TRUE)>50)]
  if (length(kept) == 0) kept <- NULL
  kept
})
```

Finally, here are the series kept given previous criterion.

```{r}
names(kept_seasons) <- unique(yelloweel_allhab$emu_nameshort)
kept_seasons[!sapply(kept_seasons,is.null)]
```


### Data preparation
We carry out the same procedure as for seasonality. 

```{r}
yelloweel_allhab_subset <- subset(yelloweel_allhab, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, yelloweel_allhab$season, yelloweel_allhab$emu_nameshort))


yelloweel_allhab_wide <- pivot_wider(data=yelloweel_allhab_subset[, c("emu_nameshort",
                                                     "cou_code",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(yelloweel_allhab_wide)[-(1:3)] <- paste("m",
                                       names(yelloweel_allhab_wide)[-(1:3)],
                                       sep="")

###we count the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(yelloweel_allhab_wide$emu_nameshort,
                        yelloweel_allhab_wide$season,
                  zero=rowSums(yelloweel_allhab_wide[, -(1:3)] == 0 |
                                 is.na(yelloweel_allhab_wide[, -(1:3)])),
           tot=rowSums(yelloweel_allhab_wide[, -(1:3)], na.rm=TRUE))
yelloweel_allhab_wide <- yelloweel_allhab_wide[data_poor$zero < 10 & data_poor$tot>50, ]
table_datapoor(data_poor %>% filter(zero > 9 | tot<50)) #we remove years where we have less than 2 months)

```


It leads to a dataset with `r nrow(yelloweel_allhab_wide)` rows. 

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months / closed months, and we compute proportions per month for each year.

```{r}
yelloweel_allhab_wide <- yelloweel_allhab_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
yelloweel_allhab_wide[, -(1:3)] <- yelloweel_allhab_wide[, -(1:3)] + 1e-3
total_catch_year <- rowSums(yelloweel_allhab_wide[, paste("m", 1:12, sep="")])
yelloweel_allhab_wide <- yelloweel_allhab_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
yelloweel_allhab_wide$period <- ifelse(yelloweel_allhab_wide$season>2009,
                                  2,
                                  1)

kable(table(yelloweel_allhab_wide$period,
       yelloweel_allhab_wide$emu_nameshort),
      row.names=TRUE,caption="number of seasons per EMU and period")
```

The situation is not well balanced. Most EMU which have data in periods 1 don't have data in period 2 and conversely.


### Running the model
```{r}
group <- as.integer(interaction(yelloweel_allhab_wide$emu_nameshort,
                                            yelloweel_allhab_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(yelloweel_allhab_wide[, paste("m", 1:12, sep="")])
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
cl <- makeCluster(3, 'FORK')
comparison <- parSapply(cl,2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         adapted <- FALSE
         while (!adapted){
           tryCatch({
             runjags.options(adapt.incomplete="error")
             res <- run.jags("jags_model.txt", monitor= c("deviance",
                                                          "alpha_group",
                                                          "cluster"),
                        summarise=FALSE, adapt=40000, method="parallel",
                        sample=2000,burnin=100000,n.chains=1,
                        inits=generate_init(nbclus, mydata)[[1]],
                        data=mydata)
                        adapted <- TRUE
                        res_mat <- as.matrix(as.mcmc.list(res))
                        silhouette <- median(compute_silhouette(res_mat))
                        nbused <- apply(res_mat, 1, function(iter){
                          length(table(iter[grep("cluster",
                                                 names(iter))]))
                        })
                        dic <- mean(res_mat[,1])+0.5*var(res_mat[,1])
                        stats <- c(dic,silhouette,mean(nbused))
                  }, error=function(e) {
                    print(paste("not adapted, restarting nbclus",nbclus))
                    }
                  )
         }
         stats
      })
stopCluster(cl)
best_yelloweel_allhab_landings <- data.frame(nbclus=2:(ncol(comparison)+1),
                                              dic=comparison[1, ],
                                              silhouette=comparison[2, ],
                                              used=comparison[3, ])
save(best_yelloweel_allhab_landings, file="yelloweel_allhab_landings_jags.rdata")
```

```{R}
load("yelloweel_allhab_landings_jags.rdata")
best_yelloweel_allhab_landings
```

The number of clusters used keep increasing, there is a good silhouette and DIC at 6.

```{r, eval=FALSE}
nbclus <- 6
mydata <-build_data(6)
adapted <- FALSE
while (!adapted){
   tryCatch({
      runjags.options(adapt.incomplete="error")
      myfit_yelloweel_allhab_landings <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=1, thin=5,
                      inits=generate_init(nbclus, mydata)[[1]], data=mydata)
      adapted <- TRUE
    }, error=function(e) {
       print(paste("not adapted, restarting nbclus",nbclus))
    })
}


save(myfit_yelloweel_allhab_landings, best_yelloweel_allhab_landings,
     file="yelloweel_allhab_landings_jags.rdata")
```

## Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("yelloweel_allhab_landings_jags.rdata")
nbclus <- 6
mydata <-build_data(6)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res, add.mutate=FALSE))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}

pat <-get_pattern_month(myfit_yelloweel_allhab_landings)
clus_order=c("1","2","5","3","6","4")
pat$cluster <- factor(match(pat$cluster, clus_order),
                       levels=as.character(1:7))

ggplot(pat,aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  scale_fill_manual(values=cols)+facet_wrap(.~cluster, ncol=1) +
  theme_igray()
```

Cluster 1 peaks in winter, 2 in spring, 3 in spring/summer, 5 is wisepread from april to november and 6 peaks in autumn (after a small peak in spring). 

We compute some statistics to characterize the clusters.
```{r}
table_characteristics(myfit_yelloweel_allhab_landings, 6, clus_order)
```

Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.


We can also look at the belonging of the different groups.
```{r}
get_pattern_month <- function(res,mydata){
  
  groups <- interaction(yelloweel_allhab_wide$emu_nameshort,
                                            yelloweel_allhab_wide$period,
                                            drop=TRUE)
  group_name <- levels(groups)
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res,add.mutate=FALSE))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", paste("clus",seq_len(nbclus),sep=""))
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_yelloweel_allhab_landings)
col_toreorder=grep("clus[0-9]",names(myclassif))
names(myclassif)[col_toreorder]=paste("clus",
                                      match(paste("clus",1:nbclus,sep=""),
                                      paste("clus",clus_order,sep="")),
                                      sep="")
myclassif[,col_toreorder] <- myclassif%>%
  select(col_toreorder)%>%select(sort(names(.)))
myclassif$cluster <- factor(match(myclassif$cluster, clus_order),
                       levels=as.character(1:7))

table_classif(myclassif)
```

Cluster 1 corresponds only to ES_Murc and cluster 6 to FR_Cors. Cluster 2 corresponds to French EMUs in transitional waters. Clusters 3 -5 are diverse. 5 accounts for French and Deutsh EMUs (T and F) and 6 to a large number of EMUs.

```{r}
myplots <-lapply(c("MO","C","T", "F"),function(hty){
  myclassif_p1 <- subset(myclassif, myclassif$period == 1 &
                           endsWith(as.character(myclassif$ser),
                                    hty))
  myclassif_p2 <- subset(myclassif, myclassif$period == 2 &
                           endsWith(as.character(myclassif$ser),
                                    hty))
  emu$cluster1 <- factor(myclassif_p1$cluster[match(emu$name_short,                                                  substr(myclassif_p1$ser,1,nchar(as.character(myclassif_p1$ser))-2))],
                       levels=1:7)
  emu$cluster2 <- factor(myclassif_p2$cluster[match(emu$name_short,                                                substr(myclassif_p2$ser,1,nchar(as.character(myclassif_p2$ser))-2))],
                       levels=1:7)
  p1 <- ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		  geom_sf(data=emu,aes(fill=cluster1)) + scale_fill_manual(values=cols)+
      theme_igray() +xlim(-20,30) + ylim(35,65) +
    ggtitle(paste("period 1",hty))
  p2 <- ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		  geom_sf(data=emu,aes(fill=cluster2)) + scale_fill_manual(values=cols)+
    theme_igray() +xlim(-20,30) + ylim(35,65)  +
    ggtitle(paste("period 2",hty))
  return(list(p1,p2))
})
myplots <- do.call(c, myplots)
print(myplots[[1]][[1]])
print(myplots[[1]][[2]])
print(myplots[[2]][[1]])
print(myplots[[2]][[2]])
print(myplots[[3]][[1]])
print(myplots[[3]][[2]])
print(myplots[[4]][[1]])
print(myplots[[4]][[2]])

```


# Silver eel
First, let's select data corresponding to silver stage.

```{r}
silver_eel <- subset(res, res$lfs_code=="S")

# we start by removing rows with only zero
all_zero <- silver_eel %>%	group_by(emu_nameshort,lfs_code,hty_code,das_year) %>%
		summarize(S=sum(das_value)) %>% 
    filter(S==0)

silver_eel <- silver_eel %>% 
	  anti_join(all_zero)

table(silver_eel$hty_code)

#We have many data, so we remove "FC" and "FTC" which are weirds mixes
silver_eel <- silver_eel %>%
  filter(!hty_code %in% c("FTC", "FC"))

#in this analysis, the unit will correspond to EMU / habitat so we create 
#corresponding column
silver_eel$emu <- silver_eel$emu_nameshort
silver_eel$emu_nameshort <- paste(silver_eel$emu_nameshort,
                                   silver_eel$hty_code, sep="_")


#There are some duplicates for IE_West_F that should be summed up according to
#Russel
summed_up_IE <-silver_eel %>%
  filter(silver_eel$emu_nameshort=="IE_West_F") %>%
  group_by(das_year,das_month) %>%
  summarize(das_value=sum(das_value))

silver_eel <- silver_eel %>% 
  distinct(das_year,das_month,emu_nameshort, .keep_all = TRUE)

silver_eel[silver_eel$emu_nameshort=="IE_West_F",
          c("das_year","das_month","das_value") ] <- summed_up_IE


```

Similarly to seasonality, we will build season. We reuse the procedure made for silver eel and silver eel seasonality, i.e. defining seasons per emu, with the season starting at the month with minimum landings. The month with lowest catch fmin define the beggining of the season (month_in_season=1) and season y stands for the 12 months from fmin y (e.g., if lowest migration is in december, season ranges from december to november, and season y denotes season from december y to november y+1).

```{r}
#creating season
silvereel <- do.call("rbind.data.frame",
                     lapply(unique(silver_eel$emu_nameshort),
                            function(s)
                              season_creation(silver_eel[silver_eel$emu_nameshort==s,])))
months_peak_per_series<- unique(silvereel[,c("emu_nameshort","peak_month")])

#large variety in the month with peak of catches among EMU / habitat
kable(table(months_peak_per_series$peak_month),
      col.names=c("month","number of EMUs"),
      caption="number of EMUs peaking in a given months")

#we remove data from season 2020
silvereel <- silvereel %>%
  filter(season < 2020)

```


Looking at the data, it seems that there are few silver eel fisheries in transitional and marine open waters, therefore, we will make an analysis for freshwater and 1 for all other environments.

```{r}
table(unique(silvereel[,c("hty_code","emu_nameshort")])$hty_code)
```


##marine open, coastal and transitional waters
### Data selection
Now we should carry out data selection, more specifically, we want to eliminate rows with two many missing data, too much zero and to check whether there are no duplicates (though Cedric already did it)

```{r, warning=FALSE}
silvereel_coastal <- subset(silvereel, silvereel$hty_code !="F")
kept_seasons <- lapply(unique(silvereel_coastal$emu_nameshort), function(s){
  sub_silver <- subset(silvereel_coastal, silvereel_coastal$emu_nameshort==s)
  kept <- good_coverage_wave(sub_silver)
  #we remove season in which we have less than 50 kg of landings
  if(!is.null(kept))
    kept <- kept[sapply(kept,function(k)
      sum(sub_silver$das_value[sub_silver$season==k],na.rm=TRUE)>50)]
  if (length(kept) == 0) kept <- NULL
  kept
})
```

Finally, here are the series kept given previous criterion.

```{r}
names(kept_seasons) <- unique(silvereel_coastal$emu_nameshort)
kept_seasons[!sapply(kept_seasons,is.null)]
```


### Data preparation
We carry out the same procedure as for seasonality. 

```{r}
silvereel_coastal_subset <- subset(silvereel_coastal, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, silvereel_coastal$season, silvereel_coastal$emu_nameshort))


silvereel_coastal_wide <- pivot_wider(data=silvereel_coastal_subset[, c("emu_nameshort",
                                                     "cou_code",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(silvereel_coastal_wide)[-(1:3)] <- paste("m",
                                       names(silvereel_coastal_wide)[-(1:3)],
                                       sep="")

###we count the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(silvereel_coastal_wide$emu_nameshort,
                        silvereel_coastal_wide$season,
                  zero=rowSums(silvereel_coastal_wide[, -(1:3)] == 0 |
                                 is.na(silvereel_coastal_wide[, -(1:3)])),
           tot=rowSums(silvereel_coastal_wide[, -(1:3)], na.rm=TRUE))
silvereel_coastal_wide <- silvereel_coastal_wide[data_poor$zero < 10 
                                                   & data_poor$tot>50, ]

table_datapoor(data_poor %>% filter(zero > 9 | tot<50)) #we remove years where we have less than 2 months)

```


It leads to a dataset with `r nrow(silvereel_coastal_wide)` rows. 

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months / closed months, and we compute proportions per month for each year.

```{r}
silvereel_coastal_wide <- silvereel_coastal_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
silvereel_coastal_wide[, -(1:3)] <- silvereel_coastal_wide[, -(1:3)] + 1e-3
total_catch_year <- rowSums(silvereel_coastal_wide[, paste("m", 1:12, sep="")])
silvereel_coastal_wide <- silvereel_coastal_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
silvereel_coastal_wide$period <- ifelse(silvereel_coastal_wide$season>2009,
                                  2,
                                  1)

kable(table(silvereel_coastal_wide$period,
       silvereel_coastal_wide$emu_nameshort),
      row.names=TRUE,
      caption="number of seasons per EMU and period")
```

The situation is not well balanced. Most EMU which have data in periods 1 don't have data in period 2 and conversely.


### Running the model
```{r}
group <- as.integer(interaction(silvereel_coastal_wide$emu_nameshort,
                                            silvereel_coastal_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(silvereel_coastal_wide[, paste("m", 1:12, sep="")])
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
cl <- makeCluster(3, 'FORK')
comparison <- parSapply(cl,2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         adapted <- FALSE
         while (!adapted){
           tryCatch({
             runjags.options(adapt.incomplete="error")
             res <- run.jags("jags_model.txt", monitor= c("deviance",
                                                          "alpha_group",
                                                          "cluster"),
                        summarise=FALSE, adapt=40000, method="parallel",
                        sample=2000,burnin=100000,n.chains=1,
                        inits=generate_init(nbclus, mydata)[[1]],
                        data=mydata)
                        adapted <- TRUE
                        res_mat <- as.matrix(as.mcmc.list(res))
                        silhouette <- median(compute_silhouette(res_mat))
                        nbused <- apply(res_mat, 1, function(iter){
                          length(table(iter[grep("cluster",
                                                 names(iter))]))
                        })
                        dic <- mean(res_mat[,1])+0.5*var(res_mat[,1])
                        stats <- c(dic,silhouette,mean(nbused))
                  }, error=function(e) {
                    print(paste("not adapted, restarting nbclus",nbclus))
                    }
                  )
         }
         stats
      })
stopCluster(cl)
best_silvereel_coastal_landings <- data.frame(nbclus=2:(ncol(comparison)+1),
                                              dic=comparison[1, ],
                                              silhouette=comparison[2, ],
                                              used=comparison[3,])
save(best_silvereel_coastal_landings, file="silvereel_coastal_landings_jags.rdata")
```

```{R}
load("silvereel_coastal_landings_jags.rdata")
best_silvereel_coastal_landings
```

4 seem to be a good compromise (though only 3 clusters seem to be effectively used)


```{r, eval=FALSE}
nbclus <- 4
mydata <-build_data(4)
adapted <- FALSE
while (!adapted){
   tryCatch({
      runjags.options(adapt.incomplete="error")
      myfit_silvereel_coastal_landings <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=1, thin=5,
                      inits=generate_init(nbclus, mydata)[[1]], data=mydata)
      adapted <- TRUE
    }, error=function(e) {
       print(paste("not adapted, restarting nbclus",nbclus))
    })
}


save(myfit_silvereel_coastal_landings, best_silvereel_coastal_landings,
     file="silvereel_coastal_landings_jags.rdata")
```

### Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("silvereel_coastal_landings_jags.rdata")
nbclus <- 4
mydata <-build_data(4)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res, add.mutate=FALSE))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}

pat <-get_pattern_month(myfit_silvereel_coastal_landings)
clus_order=c("1","3","4","2")
pat$cluster <- factor(match(pat$cluster, clus_order),
                      levels=as.character(1:7))
ggplot(pat,aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA)+facet_wrap(.~cluster, ncol=1) +
  theme_igray()
```
Clusters 3 and 4 correspond to peak in october with 3 more widespread. Cluster 1 corresponds to a peak in autumn/winter. Cluster 2 corresponds to catches in winter.

We compute some statistics to characterize the clusters.

```{r}
table_characteristics(myfit_silvereel_coastal_landings, 4,clus_order)
```

Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.


We can also look at the belonging of the different groups.
```{r}
groups <- interaction(silvereel_coastal_wide$emu_nameshort,
                                            silvereel_coastal_wide$period,
                                            drop=TRUE)
group_name <- levels(groups)

get_pattern_month <- function(res,mydata){
  
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res,add.mutate=FALSE))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", paste("clus",seq_len(nbclus),sep=""))
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_silvereel_coastal_landings)
col_toreorder=grep("clus[0-9]",names(myclassif))
names(myclassif)[col_toreorder]=paste("clus",
                                      match(paste("clus",1:nbclus,sep=""),
                                      paste("clus",clus_order,sep="")),
                                      sep="")
myclassif[,col_toreorder] <- myclassif%>%
  select(col_toreorder)%>%select(sort(names(.)))
myclassif$cluster <- factor(match(myclassif$cluster,clus_order ),
                      levels=as.character(1:7))
table_classif(myclassif)
```

In fact, most EMUs fall in cluster 3. Cluster 2 corresponds only to ES_Murc_C (same as for yellow eel) and one for FR_Cors. Cluster 4 (limited fishing season) regroups GB and DE EMUs.

```{r}
myplots <-lapply(c("MO","C","T"),function(hty){
  myclassif_p1 <- subset(myclassif, myclassif$period == 1 &
                           endsWith(as.character(myclassif$ser),
                                    hty))
  myclassif_p2 <- subset(myclassif, myclassif$period == 2 &
                           endsWith(as.character(myclassif$ser),
                                    hty))
  emu$cluster1 <- factor(myclassif_p1$cluster[match(emu$name_short,                                                  gsub(paste("_",hty,sep=""),"",myclassif_p1$ser))],
                       levels=1:7)
  emu$cluster2 <- factor(myclassif_p2$cluster[match(emu$name_short,                                                gsub(paste("_",hty,sep=""),"",myclassif_p2$ser))],
                       levels=1:7)
  p1 <- ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		  geom_sf(data=emu,aes(fill=cluster1)) + scale_fill_manual(values=cols)+
      theme_igray() +xlim(-20,30) + ylim(35,65) +
    ggtitle(paste("period 1",hty))
  p2 <- ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		  geom_sf(data=emu,aes(fill=cluster2)) + scale_fill_manual(values=cols)+
    theme_igray() +xlim(-20,30) + ylim(35,65)  +
    ggtitle(paste("period 2",hty))
  return(list(p1,p2))
})
print(myplots[[2]][[1]])
print(myplots[[2]][[2]])
print(myplots[[3]][[1]])
print(myplots[[3]][[2]])
```

### Exporting pattern per group
```{r}
tmp <- as.matrix(as.mcmc.list(myfit_silvereel_coastal_landings))
name_col = colnames(tmp)

pattern_Smar_coast_trans_landings=do.call("rbind.data.frame",
                                lapply(seq_len(length(levels(groups))), function(g)
                                   median_pattern_group(g, group_name,tmp, "S","landings")))
save(pattern_Smar_coast_trans_landings,file="pattern_Smar_coast_trans_landings.rdata")
```

### Similarity between and after 2010
```{r}
#which groups have data in both periods
occ=table(unique(silvereel_coastal_wide[,c("emu_nameshort", "period")])[,1])
tocompare=names(occ)[which(occ>1)]

simi=sapply(tocompare, function(s){
  g=grep(s,group_name)
  esp1=tmp[,grep(paste("alpha_group\\[",g[1],",",sep=""),name_col)]
  esp2=tmp[,grep(paste("alpha_group\\[",g[2],",",sep=""),name_col)]
  quantile(apply(cbind(esp1,esp2),
                 1,
                 function(x) sum(pmin(x[1:12],x[13:24]))),
           probs=c(0.025,.5,.975))
})

similarity=data.frame(emu=tocompare,t(simi))

table_similarity(similarity)
```

### Potential effect of EMP and EU closures
```{r}
ncar=nchar(group_name)
period=as.integer(substr(as.character(group_name),ncar,ncar))
blocks=strsplit(group_name,"_")
emus=sapply(blocks,function(x)paste(x[1],x[2],sep="_"))
hty_code=sapply(blocks,function(x) substr(x[3],1,nchar(x[3])-2))



#######EMP
list_period1=data.frame(emu_nameshort=emus[period==1])
list_period1$group=group_name[period==1]
list_period1$id_g=match(list_period1$group,group_name)
list_period1$hty_code=hty_code[period==1]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period1$estimable=mapply(function(s,hty) {
  length(which(charac_EMP_closures$emu_nameshort==s 
               & grepl("S",charac_EMP_closures$lfs_code) 
               & grepl(hty, charac_EMP_closures$hty_code)))>0},
  list_period1$emu_nameshort, list_period1$hty_code)

list_period1$estimable=list_period1$estimable &
(sapply(list_period1$id_g,function(e) min(silvereel_coastal_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EMP_closures$year[charac_EMP_closures$emu_nameshort==e &
                                                           grepl("S",charac_EMP_closures$lfs_code) &
                                                    grepl(hty,charac_EMP_closures$hty_code)]),
       list_period1$emu_nameshort, list_period1$hty_code))

list_period1$lossq2.5=NA
list_period1$lossq50=NA
list_period1$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EMP_closures %>%
    filter(emu_nameshort==s & grepl("S",lfs_code) & grepl(hty, hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period1$emu_nameshort[list_period1$estimable]),
list_period1$id_g[list_period1$estimable],
list_period1$hty[list_period1$estimable])

list_period1[list_period1$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period1[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EMP closure",
      digits=2)







#######EU
list_period2=data.frame(emu_nameshort=emus[period==2])
list_period2$group=group_name[period==2]
list_period2$id_g=match(list_period2$group,group_name)
list_period2$hty_code=hty_code[period==2]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period2$estimable=mapply(function(s,hty) {
  length(which(charac_EU_closures$emu_nameshort==s 
               & grepl("S",charac_EU_closures$lfs_code) 
               & grepl(hty, charac_EU_closures$hty_code)))>0},
  list_period2$emu_nameshort, list_period2$hty_code)

list_period2$estimable=list_period2$estimable &
(sapply(list_period2$id_g,function(e) min(silvereel_coastal_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EU_closures$year[charac_EU_closures$emu_nameshort==e &
                                                           grepl("S",charac_EU_closures$lfs_code) &
                                                    grepl(hty,charac_EU_closures$hty_code)]),
       list_period2$emu_nameshort, list_period2$hty_code))

list_period2$lossq2.5=NA
list_period2$lossq50=NA
list_period2$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EU_closures %>%
    filter(emu_nameshort==s & grepl("S", lfs_code) & grepl(hty,hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period2$emu_nameshort[list_period2$estimable]),
list_period2$id_g[list_period2$estimable],
list_period2$hty_code[list_period2$estimable])

list_period2[list_period2$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period2[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EU closure",
      digits=2)

list_period2$type="EU closure"
list_period1$type="EMP closure"
list_period=rbind.data.frame(list_period1,list_period2)
list_period$stage="S"
save(list_period,file="loss_silvercoastal.rdata")




####scenario per cluster
starts_closure=8:12
clus=1:nbclus
experiments=expand.grid(clus,starts_closure)
effects=t(mapply(function(c,s){
  months_closed=(s:(s+2))
  months_closed=ifelse(months_closed>12,months_closed-12,months_closed)
  pattern=tmp[,grep(paste("esp\\[",c,",",sep=""),colnames(tmp))]
  effect=rowSums(pattern[,months_closed])
  quantile(effect,probs=c(0.025,.5,.975))
},experiments[,1],experiments[,2]))
effects_scenario=data.frame(cluster=match(experiments[,1],clus_order),
                            starting_month_EU_closure=experiments[,2],
                            loss_median=effects[,2],
                            loss_2.5=effects[,1],
                            loss_97.5=effects[,3])
effects_scenario=effects_scenario[order(effects_scenario$cluster,
                                        effects_scenario$starting_month_EU_closure),]


kable(effects_scenario,row.names=FALSE,col.names=c("cluster",
                                   "speculative 1st month of EU closure",
                                   "median loss of catch",
                                   "q2.5",
                                   "q97.5"), digits=2,
      caption="potential effect that an EU closure would have depending on cluster and starting month")

```


##freshwater waters
### Data selection
Now we should carry out data selection, more specifically, we want to eliminate rows with two many missing data, too much zero and to check whether there are no duplicates (though Cedric already did it)

```{r, warning=FALSE}
silvereel_freshwater <- subset(silvereel, silvereel$hty_code =="F")
kept_seasons <- lapply(unique(silvereel_freshwater$emu_nameshort), function(s){
  sub_silver <- subset(silvereel_freshwater, silvereel_freshwater$emu_nameshort==s)
  kept <- good_coverage_wave(sub_silver)
  #we remove season in which we have less than 50 kg of landings
  if(!is.null(kept))
    kept <- kept[sapply(kept,function(k)
      sum(sub_silver$das_value[sub_silver$season==k],na.rm=TRUE)>50)]
  if (length(kept) == 0) kept <- NULL
  kept
})
```

Finally, here are the series kept given previous criterion.

```{r}
names(kept_seasons) <- unique(silvereel_freshwater$emu_nameshort)
kept_seasons[!sapply(kept_seasons,is.null)]
```


### Data preparation
We carry out the same procedure as for seasonality. 

```{r}
silvereel_freshwater_subset <- subset(silvereel_freshwater, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, silvereel_freshwater$season, silvereel_freshwater$emu_nameshort))


silvereel_freshwater_wide <- pivot_wider(data=silvereel_freshwater_subset[, c("emu_nameshort",
                                                     "cou_code",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(silvereel_freshwater_wide)[-(1:3)] <- paste("m",
                                       names(silvereel_freshwater_wide)[-(1:3)],
                                       sep="")

###we count the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(silvereel_freshwater_wide$emu_nameshort,
                        silvereel_freshwater_wide$season,
                  zero=rowSums(silvereel_freshwater_wide[, -(1:3)] == 0 |
                                 is.na(silvereel_freshwater_wide[, -(1:3)])),
           tot=rowSums(silvereel_freshwater_wide[, -(1:3)], na.rm=TRUE))
silvereel_freshwater_wide <- silvereel_freshwater_wide[data_poor$zero < 10 
                                                   & data_poor$tot>50, ]
table_datapoor(data_poor %>% filter(zero > 9 | tot<50)) #we remove years where we have less than 2 months)

```


It leads to a dataset with `r nrow(silvereel_freshwater_wide)` rows. 

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months / closed months, and we compute proportions per month for each year.

```{r}
silvereel_freshwater_wide <- silvereel_freshwater_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
silvereel_freshwater_wide[, -(1:3)] <- silvereel_freshwater_wide[, -(1:3)] + 1e-3
total_catch_year <- rowSums(silvereel_freshwater_wide[, paste("m", 1:12, sep="")])
silvereel_freshwater_wide <- silvereel_freshwater_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
silvereel_freshwater_wide$period <- ifelse(silvereel_freshwater_wide$season>2009,
                                  2,
                                  1)

kable(table(silvereel_freshwater_wide$period,
       silvereel_freshwater_wide$emu_nameshort),
      row.names=TRUE,
      caption="number of season per EMU and period")
```

The situation is not well balanced. Most EMU have data only after 2010.


### Running the model
```{r}
group <- as.integer(interaction(silvereel_freshwater_wide$emu_nameshort,
                                            silvereel_freshwater_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(silvereel_freshwater_wide[, paste("m", 1:12, sep="")])
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
cl <- makeCluster(3, 'FORK')
comparison <- parSapply(cl,2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         adapted <- FALSE
         while (!adapted){
           tryCatch({
             runjags.options(adapt.incomplete="error")
             res <- run.jags("jags_model.txt", monitor= c("deviance",
                                                          "alpha_group",
                                                          "cluster"),
                        summarise=FALSE, adapt=40000, method="parallel",
                        sample=2000,burnin=100000,n.chains=1,
                        inits=generate_init(nbclus, mydata)[[1]],
                        data=mydata)
                        adapted <- TRUE
                        res_mat <- as.matrix(as.mcmc.list(res))
                        silhouette <- median(compute_silhouette(res_mat))
                        nbused <- apply(res_mat, 1, function(iter){
                          length(table(iter[grep("cluster",
                                                 names(iter))]))
                        })
                        dic <- mean(res_mat[,1])+0.5*var(res_mat[,1])
                        stats <- c(dic,silhouette,mean(nbused))
                  }, error=function(e) {
                    print(paste("not adapted, restarting nbclus",nbclus))
                    }
                  )
         }
         stats
      })
stopCluster(cl)
best_silvereel_freshwater_landings <- data.frame(nbclus=2:(ncol(comparison)+1),
                                              dic=comparison[1, ],
                                              silhouette=comparison[2, ],
                                              used=comparison[3,])
save(best_silvereel_freshwater_landings, file="silvereel_freshwater_landings_jags.rdata")
```

```{R}
load("silvereel_freshwater_landings_jags.rdata")
best_silvereel_freshwater_landings
```

5 seem to be a good compromise: slight decrease in silhouette, but all clusters are used and DIC is good.


```{r, eval=FALSE}
nbclus <- 5
mydata <-build_data(5)
adapted <- FALSE
while (!adapted){
   tryCatch({
      runjags.options(adapt.incomplete="error")
      myfit_silvereel_freshwater_landings <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=1, thin=5,
                      inits=generate_init(nbclus, mydata)[[1]], data=mydata)
      adapted <- TRUE
    }, error=function(e) {
       print(paste("not adapted, restarting nbclus",nbclus))
    })
}


save(myfit_silvereel_freshwater_landings, best_silvereel_freshwater_landings,
     file="silvereel_freshwater_landings_jags.rdata")
```

### Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("silvereel_freshwater_landings_jags.rdata")
nbclus <- 5
mydata <-build_data(5)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res, add.mutate=FALSE))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}

pat <-get_pattern_month(myfit_silvereel_freshwater_landings)
clus_order=c("4","1","5","2","3")
pat$cluster <- factor(match(pat$cluster, clus_order),
                      levels=as.character(1:7))
ggplot(pat,aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  scale_fill_manual(values=cols)+facet_wrap(.~cluster, ncol=1) +
  theme_igray()
```

Cluster 2 peaks in summer with a second peak in december, 5 in winter, 2 in summer. Clusters 1 and 3 are bivariate (spring and autumn).

We compute some statistics to characterize the clusters.
```{r}
table_characteristics(myfit_silvereel_freshwater_landings, 5,clus_order)
```

Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.


We can also look at the belonging of the different groups.
```{r}
groups <- interaction(silvereel_freshwater_wide$emu_nameshort,
                                            silvereel_freshwater_wide$period,
                                            drop=TRUE)
group_name <- levels(groups)
  
get_pattern_month <- function(res,mydata){
  
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res,add.mutate=FALSE))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", paste("clus",seq_len(nbclus),sep=""))
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_silvereel_freshwater_landings)
col_toreorder=grep("clus[0-9]",names(myclassif))
names(myclassif)[col_toreorder]=paste("clus",
                                      match(paste("clus",1:nbclus,sep=""),
                                      paste("clus",clus_order,sep="")),
                                      sep="")
myclassif[,col_toreorder] <- myclassif%>%
  select(col_toreorder)%>%select(sort(names(.)))
myclassif$cluster <- factor(match(myclassif$cluster,clus_order ),
                      levels=as.character(1:7))
table_classif(myclassif)
```

Once again the spatial pattern is obvious. SE_Inla changed from 1 to 2 suggesting a reduction in the fishing season.

```{r}
myclassif_p1 <- subset(myclassif, myclassif$period == 1)
myclassif_p2 <- subset(myclassif, myclassif$period == 2)
emu$cluster1 <- factor(myclassif_p1$cluster[match(emu$name_short,
                                                  substr(myclassif_p1$ser,1,nchar(as.character(myclassif_p1$ser))-2))],
                       levels=1:7)
emu$cluster2 <- factor(myclassif_p2$cluster[match(emu$name_short,
                                                substr(myclassif_p2$ser,1,nchar(as.character(myclassif_p2$ser))-2))],
                       levels=1:7)
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster1)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65) 
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_sf(data=emu,aes(fill=cluster2)) + scale_fill_manual(values=cols)+
  theme_igray() +xlim(-20,30) + ylim(35,65)  

```


### Exporting pattern per group
```{r}
tmp <- as.matrix(as.mcmc.list(myfit_silvereel_freshwater_landings))
name_col = colnames(tmp)

pattern_Sfresh_landings=do.call("rbind.data.frame",
                                lapply(seq_len(length(levels(groups))), function(g)
                                   median_pattern_group(g, group_name,tmp, "Y","landings")))
save(pattern_Sfresh_landings,file="pattern_Sfresh_landings.rdata")
```

### Similarity between and after 2010
```{r}
#which groups have data in both periods
occ=table(unique(silvereel_freshwater_wide[,c("emu_nameshort", "period")])[,1])
tocompare=names(occ)[which(occ>1)]

simi=sapply(tocompare, function(s){
  g=grep(s,group_name)
  esp1=tmp[,grep(paste("alpha_group\\[",g[1],",",sep=""),name_col)]
  esp2=tmp[,grep(paste("alpha_group\\[",g[2],",",sep=""),name_col)]
  quantile(apply(cbind(esp1,esp2),
                 1,
                 function(x) sum(pmin(x[1:12],x[13:24]))),
           probs=c(0.025,.5,.975))
})

similarity=data.frame(emu=tocompare,t(simi))

table_similarity(similarity)
```

### Potential effect of EMP and EU closures
```{r}
ncar=nchar(group_name)
period=as.integer(substr(as.character(group_name),ncar,ncar))
blocks=strsplit(group_name,"_")
emus=sapply(blocks,function(x)paste(x[1],x[2],sep="_"))
hty_code=sapply(blocks,function(x) substr(x[3],1,nchar(x[3])-2))



#######EMP
list_period1=data.frame(emu_nameshort=emus[period==1])
list_period1$group=group_name[period==1]
list_period1$id_g=match(list_period1$group,group_name)
list_period1$hty_code=hty_code[period==1]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period1$estimable=mapply(function(s,hty) {
  length(which(charac_EMP_closures$emu_nameshort==s 
               & grepl("S",charac_EMP_closures$lfs_code) 
               & grepl(hty, charac_EMP_closures$hty_code)))>0},
  list_period1$emu_nameshort, list_period1$hty_code)

list_period1$estimable=list_period1$estimable &
(sapply(list_period1$id_g,function(e) min(silvereel_freshwater_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EMP_closures$year[charac_EMP_closures$emu_nameshort==e &
                                                           grepl("S",charac_EMP_closures$lfs_code) &
                                                    grepl(hty,charac_EMP_closures$hty_code)]),
       list_period1$emu_nameshort, list_period1$hty_code))

list_period1$lossq2.5=NA
list_period1$lossq50=NA
list_period1$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EMP_closures %>%
    filter(emu_nameshort==s & grepl("S",lfs_code) & grepl(hty, hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period1$emu_nameshort[list_period1$estimable]),
list_period1$id_g[list_period1$estimable],
list_period1$hty[list_period1$estimable])

list_period1[list_period1$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period1[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EMP closure",
      digits=2)







#######EU
list_period2=data.frame(emu_nameshort=emus[period==2])
list_period2$group=group_name[period==2]
list_period2$id_g=match(list_period2$group,group_name)
list_period2$hty_code=hty_code[period==2]
  
#we check that we have ladings data at least two years before the first EMP closures
list_period2$estimable=mapply(function(s,hty) {
  length(which(charac_EU_closures$emu_nameshort==s 
               & grepl("S",charac_EU_closures$lfs_code) 
               & grepl(hty, charac_EU_closures$hty_code)))>0},
  list_period2$emu_nameshort, list_period2$hty_code)

list_period2$estimable=list_period2$estimable &
(sapply(list_period2$id_g,function(e) min(silvereel_freshwater_wide$season[group==e]))+2 <
mapply(function(e,hty) min(charac_EU_closures$year[charac_EU_closures$emu_nameshort==e &
                                                           grepl("S",charac_EU_closures$lfs_code) &
                                                    grepl(hty,charac_EU_closures$hty_code)]),
       list_period2$emu_nameshort, list_period2$hty_code))

list_period2$lossq2.5=NA
list_period2$lossq50=NA
list_period2$lossq97.5=NA

res_closures=mapply(function(s,g,hty) {
  emu_closures <- EU_closures %>%
    filter(emu_nameshort==s & grepl("S", lfs_code) & grepl(hty,hty_code)) %>%
    group_by(emu_nameshort,month) %>%
    summarize(fishery_closure_percent=max(fishery_closure_percent))
  myalpha=tmp[,paste("alpha_group[",g,",",emu_closures$month,"]",sep="")]
  if (nrow(emu_closures)>1){
    loss=colSums(apply(myalpha,1,function(x) x*emu_closures$fishery_closure_percent/100))
  } else {
    loss=myalpha*emu_closures$fishery_closure_percent/100
  }
  quantile(loss,probs=c(0.025,.5,.975))
},as.character(list_period2$emu_nameshort[list_period2$estimable]),
list_period2$id_g[list_period2$estimable],
list_period2$hty_code[list_period2$estimable])

list_period2[list_period2$estimable, c("lossq2.5", "lossq50","lossq97.5")] =
  t(res_closures)

kable(list_period2[,c("emu_nameshort","lossq2.5","lossq50","lossq97.5")],
      col.names=c("emu","q2.5","median","q97.5"),
      caption="proportion of catch potentially lost because of EU closure",
      digits=2)



list_period2$type="EU closure"
list_period1$type="EMP closure"
list_period=rbind.data.frame(list_period1,list_period2)
list_period$stage="S"
save(list_period,file="loss_silverfresh.rdata")


####scenario per cluster
starts_closure=8:12
clus=1:nbclus
experiments=expand.grid(clus,starts_closure)
effects=t(mapply(function(c,s){
  months_closed=(s:(s+2))
  months_closed=ifelse(months_closed>12,months_closed-12,months_closed)
  pattern=tmp[,grep(paste("esp\\[",c,",",sep=""),colnames(tmp))]
  effect=rowSums(pattern[,months_closed])
  quantile(effect,probs=c(0.025,.5,.975))
},experiments[,1],experiments[,2]))
effects_scenario=data.frame(cluster=match(experiments[,1],clus_order),
                            starting_month_EU_closure=experiments[,2],
                            loss_median=effects[,2],
                            loss_2.5=effects[,1],
                            loss_97.5=effects[,3])
effects_scenario=effects_scenario[order(effects_scenario$cluster,
                                        effects_scenario$starting_month_EU_closure),]


kable(effects_scenario,row.names=FALSE,col.names=c("cluster",
                                   "speculative 1st month of EU closure",
                                   "median loss of catch",
                                   "q2.5",
                                   "q97.5"), digits=2,
      caption="potential effect that an EU closure would have depending on cluster and starting month")

```



# Siver/Yellow
Many EMUs were not able to provide landings data in which yellow and silver eel were discriminated. In such situation, it was impossible to decide a priori if such EMU should be analysed with either silver eel or yellow eel stage. Therefore, we analysed such EMUs indepedently.

```{r}
YS_eel <- subset(res, res$lfs_code=="YS")

# we start by removing rows with only zero
all_zero <- YS_eel %>%	group_by(emu_nameshort,lfs_code,hty_code,das_year) %>%
		summarize(S=sum(das_value)) %>% 
    filter(S==0)

YS_eel <- YS_eel %>% 
	  anti_join(all_zero)

table(YS_eel$hty_code)

#We have many data, so we remove "FC" and "FTC" which are weirds mixes
YS_eel <- YS_eel %>%
  filter(!hty_code %in% c("FTC", "FC"))

#in this analysis, the unit will correspond to EMU / habitat so we create 
#corresponding column
YS_eel$emu <- YS_eel$emu_nameshort
YS_eel$emu_nameshort <- paste(YS_eel$emu_nameshort,
                                   YS_eel$hty_code, sep="_")

```

Similarly to seasonality, we will build season. We reuse the procedure made for silver eel and YS eel seasonality, i.e. defining seasons per emu, with the season starting at the month with minimum landings. The month with lowest catch fmin define the beggining of the season (month_in_season=1) and season y stands for the 12 months from fmin y (e.g., if lowest migration is in december, season ranges from december to november, and season y denotes season from december y to november y+1).

```{r}
#creating season
YSeel <- do.call("rbind.data.frame",
                     lapply(unique(YS_eel$emu_nameshort),
                            function(s)
                              season_creation(YS_eel[YS_eel$emu_nameshort==s,])))
months_peak_per_series<- unique(YSeel[,c("emu_nameshort","peak_month")])

#large variety in the month with peak of catches among EMU / habitat
table(months_peak_per_series$peak_month)

#we remove data from season 2020
YSeel <- YSeel %>%
  filter(season < 2020)

```



Looking at the data, it seems that there are EMUS, therefore we will analysed all habitats simultaneously.

```{r}
table(unique(YSeel[,c("hty_code","emu_nameshort")])$hty_code)
```



## Data selection
Now we should carry out data selection, more specifically, we want to eliminate rows with two many missing data, too much zero and to check whether there are no duplicates (though Cedric already did it)

```{r, warning=FALSE}
YSeel_allhab <- YSeel
kept_seasons <- lapply(unique(YSeel_allhab$emu_nameshort), function(s){
  sub_YS <- subset(YSeel_allhab, YSeel_allhab$emu_nameshort==s)
  kept <- good_coverage_wave(sub_YS)
  #we remove season in which we have less than 50 kg of landings
  if(!is.null(kept))
    kept <- kept[sapply(kept,function(k)
      sum(sub_YS$das_value[sub_YS$season==k],na.rm=TRUE)>50)]
  if (length(kept) == 0) kept <- NULL
  kept
})
```

Finally, here are the series kept given previous criterion.

```{r}
names(kept_seasons) <- unique(YSeel_allhab$emu_nameshort)
kept_seasons[!sapply(kept_seasons,is.null)]
```


## Data preparation
We carry out the same procedure as for seasonality. 

```{r}
YSeel_allhab_subset <- subset(YSeel_allhab, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, YSeel_allhab$season, YSeel_allhab$emu_nameshort))


YSeel_allhab_wide <- pivot_wider(data=YSeel_allhab_subset[, c("emu_nameshort",
                                                     "cou_code",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(YSeel_allhab_wide)[-(1:3)] <- paste("m",
                                       names(YSeel_allhab_wide)[-(1:3)],
                                       sep="")

###we count the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(YSeel_allhab_wide$emu_nameshort,
                        YSeel_allhab_wide$season,
                  zero=rowSums(YSeel_allhab_wide[, -(1:3)] == 0 |
                                 is.na(YSeel_allhab_wide[, -(1:3)])),
           tot=rowSums(YSeel_allhab_wide[, -(1:3)], na.rm=TRUE))
YSeel_allhab_wide <- YSeel_allhab_wide[data_poor$zero < 10 & data_poor$tot>50, ]

table_datapoor(data_poor %>% filter(zero > 9 | tot <50)) #we remove years where we have less than 2 months


```


It leads to a dataset with `r nrow(YSeel_allhab_wide)` rows. 

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months / closed months, and we compute proportions per month for each year.

```{r}
YSeel_allhab_wide <- YSeel_allhab_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
YSeel_allhab_wide[, -(1:3)] <- YSeel_allhab_wide[, -(1:3)] + 1e-3
total_catch_year <- rowSums(YSeel_allhab_wide[, paste("m", 1:12, sep="")])
YSeel_allhab_wide <- YSeel_allhab_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```


The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
YSeel_allhab_wide$period <- ifelse(YSeel_allhab_wide$season>2009,
                                  2,
                                  1)

kable(table(YSeel_allhab_wide$period,
       YSeel_allhab_wide$emu_nameshort),
      row.names=TRUE,
      caption="number of seasons per EMU and period")
```

The situation is not well balanced. Most EMU which have data in periods 1 don't have data in period 2 and conversely.


## Running the model
```{r}
group <- as.integer(interaction(YSeel_allhab_wide$emu_nameshort,
                                            YSeel_allhab_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(YSeel_allhab_wide[, paste("m", 1:12, sep="")])
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
cl <- makeCluster(3, 'FORK')
comparison <- parSapply(cl,2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         adapted <- FALSE
         while (!adapted){
           tryCatch({
             runjags.options(adapt.incomplete="error")
             res <- run.jags("jags_model.txt", monitor= c("deviance",
                                                          "alpha_group",
                                                          "cluster"),
                        summarise=FALSE, adapt=40000, method="parallel",
                        sample=2000,burnin=100000,n.chains=1,
                        inits=generate_init(nbclus, mydata)[[1]],
                        data=mydata)
                        adapted <- TRUE
                        res_mat <- as.matrix(as.mcmc.list(res))
                        silhouette <- median(compute_silhouette(res_mat))
                        nbused <- apply(res_mat, 1, function(iter){
                          length(table(iter[grep("cluster",
                                                 names(iter))]))
                        })
                        dic <- mean(res_mat[,1])+0.5*var(res_mat[,1])
                        stats <- c(dic,silhouette,mean(nbused))
                  }, error=function(e) {
                    print(paste("not adapted, restarting nbclus",nbclus))
                    }
                  )
         }
         stats
      })
stopCluster(cl)
best_YSeel_allhab_landings <- data.frame(nbclus=2:(ncol(comparison)+1),
                                              dic=comparison[1, ],
                                              silhouette=comparison[2, ],
                                              used=comparison[3, ])
save(best_YSeel_allhab_landings, file="YSeel_allhab_landings_jags.rdata")
```

```{R}
load("YSeel_allhab_landings_jags.rdata")
best_YSeel_allhab_landings
```

The number of clusters used keep increasing, there is a good silhouette and DIC at 6.

```{r, eval=FALSE}
nbclus <- 6
mydata <-build_data(6)
adapted <- FALSE
while (!adapted){
   tryCatch({
      runjags.options(adapt.incomplete="error")
      myfit_YSeel_allhab_landings <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=1, thin=5,
                      inits=generate_init(nbclus, mydata)[[1]], data=mydata)
      adapted <- TRUE
    }, error=function(e) {
       print(paste("not adapted, restarting nbclus",nbclus))
    })
}


save(myfit_YSeel_allhab_landings, best_YSeel_allhab_landings,
     file="YSeel_allhab_landings_jags.rdata")
```

## Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("YSeel_allhab_landings_jags.rdata")
nbclus <- 6
mydata <-build_data(6)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res, add.mutate=FALSE))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}

pat <-get_pattern_month(myfit_YSeel_allhab_landings)
clus_order=c("3","6","4","2","1","5")
pat$cluster = factor(match(pat$cluster, clus_order),
                     levels=as.character(1:7))
ggplot(pat,aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  scale_fill_manual(values=cols)+facet_wrap(.~cluster, ncol=1)
  theme_igray()
```

Cluster 5 peaks autumn and winter, 6 is similar but shifter 1 month later. Clusters 1 and 2 are widepread with a peak in spring/early summer and a second one un autumn. Cluster 4 is located in autumn only and cluster 3 in summer.

We compute some statistics to characterize the clusters.
```{r}
table_characteristics(myfit_YSeel_allhab_landings, 6, clus_order)
```

Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.


We can also look at the belonging of the different groups.
```{r}
groups <- interaction(YSeel_allhab_wide$emu_nameshort,
                                            YSeel_allhab_wide$period,
                                            drop=TRUE)
group_name <- levels(groups)

get_pattern_month <- function(res,mydata){

  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res,add.mutate=FALSE))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", paste("clus",seq_len(nbclus),sep=""))
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_YSeel_allhab_landings)
col_toreorder=grep("clus[0-9]",names(myclassif))
names(myclassif)[col_toreorder]=paste("clus",
                                      match(paste("clus",1:nbclus,sep=""),
                                      paste("clus",clus_order,sep="")),
                                      sep="")
myclassif[,col_toreorder] <- myclassif%>%
  select(col_toreorder)%>%select(sort(names(.)))
myclassif$cluster = factor(match(myclassif$cluster, clus_order),
                     levels=as.character(1:7))

table_classif(myclassif)
```

Cluster 6 corresponds only to ES_Murc and cluster 5 to ES_Cata to FR_Cors. Cluster 1 corresponds to many French EMUs in transitional waters and 2 and  to 3 are diverse. 

```{r}
myplots <-lapply(c("TC","C","T", "F"),function(hty){
  myclassif_p1 <- subset(myclassif, myclassif$period == 1 &
                           endsWith(as.character(myclassif$ser),
                                    hty))
  myclassif_p2 <- subset(myclassif, myclassif$period == 2 &
                           endsWith(as.character(myclassif$ser),
                                    hty))
  emu$cluster1 <- factor(myclassif_p1$cluster[match(emu$name_short,                                                  gsub(paste("_",hty,sep=""),"",as.character(myclassif_p1$ser)))],
                       levels=1:7)
  emu$cluster2 <- factor(myclassif_p2$cluster[match(emu$name_short,                                                gsub(paste("_",hty,sep=""),"",as.character(myclassif_p1$ser)))],
                       levels=1:7)
  p1 <- ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		  geom_sf(data=emu,aes(fill=cluster1)) + scale_fill_manual(values=cols)+
      theme_igray() +xlim(-20,30) + ylim(35,65) +
    ggtitle(paste("period 1",hty))
  p2 <- ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		  geom_sf(data=emu,aes(fill=cluster2)) + scale_fill_manual(values=cols)+
    theme_igray() +xlim(-20,30) + ylim(35,65)  +
    ggtitle(paste("period 2",hty))
  return(list(p1,p2))
})
myplots <- do.call(c, myplots)
print(myplots[[1]][[1]])
print(myplots[[1]][[2]])
print(myplots[[2]][[1]])
print(myplots[[2]][[2]])
print(myplots[[3]][[1]])
print(myplots[[3]][[2]])
print(myplots[[4]][[1]])
print(myplots[[4]][[2]])

```

## Exporting pattern per group
```{r}
tmp <- as.matrix(as.mcmc.list(myfit_YSeel_allhab_landings))
name_col = colnames(tmp)

pattern_YS_landings=do.call("rbind.data.frame",
                                lapply(seq_len(length(levels(groups))), function(g)
                                   median_pattern_group(g, group_name,tmp, "YS","landings")))
save(pattern_YS_landings,file="pattern_YS_landings.rdata")
```


## Similarity between and after 2010
```{r}
#which groups have data in both periods
occ=table(unique(YSeel_allhab_wide[,c("emu_nameshort", "period")])[,1])
tocompare=names(occ)[which(occ>1)]

simi=sapply(tocompare, function(s){
  g=grep(s,group_name)
  esp1=tmp[,grep(paste("alpha_group\\[",g[1],",",sep=""),name_col)]
  esp2=tmp[,grep(paste("alpha_group\\[",g[2],",",sep=""),name_col)]
  quantile(apply(cbind(esp1,esp2),
                 1,
                 function(x) sum(pmin(x[1:12],x[13:24]))),
           probs=c(0.025,.5,.975))
})

similarity=data.frame(emu=tocompare,t(simi))

table_similarity(similarity)
```

