---
title: "Untitled"
author: "Hilaire Drouineau"
date: "12 janvier 2020"
output: md_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,round)
library(tidyverse)
library(tidyr)
library(runjags)
library(coda)
library(ggplot2)
```

# Loading the data
```{r loading}
wdsource <-"~/Documents/Bordeaux/migrateurs/WGEEL/wkeelmigration/source/"
load(paste(wdsource,"seasonality_tibbles_res_ser2.Rdata",sep=""))
```

Number of data series per stage: 12 pure glass eel stage, 6 pure silver and 32 yellow. Only 20 mixed series, we will have to check their classification.
```{r}
table(ser2$ser_lfs_code)
```

Among mixed GY, only 4 of them are not already used by the WGEEL, so we will have to check. For the others, we can use the wgeel classification.
```{r}
ser2[ser2$ser_lfs_code=="GY", c("ser_nameshort","ser_comment","ser_lfs_code")]
```


# Glass Eel
## Data availability
Given comments, mixed GY can be used as glass eel. What about availability across months? Very few series are collected across all months. Esti: I guess that in most on the cases the peak and the sourronding months are provided, in the rest the abundance should be low.... could the missing months be estimated using the trend of that season? ShiF, ShiM, ImsaGY, Gry, GiSc, GarG seem to have a good monthly coverage. 


```{r}
recruitment <- subset(res, res$ser_nameshort %in% ser2$ser_nameshort[ser2$ser_lfs_code %in% c("G","GY")])
table(recruitment$das_month,recruitment$ser_nameshort)

```

How many years are complete for all months?
```{r}
sapply(unique(recruitment$ser_nameshort),function(s)
  sum(colSums(table(recruitment$das_month[recruitment$ser_nameshort==s],
                    recruitment$das_year[recruitment$ser_nameshort==s])==1)==12))
```


## Data selection
First, we need to set up season of migration instead of calendar year. Here, we split in november and a sesaon y will correspond to november - december y-1 and january to october y.

```{r}
recruitment$season <- ifelse(recruitment$das_month>10,
                             recruitment$das_year+1,
                             recruitment$das_year)
recruitment$month_in_season <- paste("m",ifelse(recruitment$das_month>10,
                                      recruitment$das_month-10,
                                      recruitment$das_month+2), #1 stands for nov,
                                      sep="")                   #2 dec, 3 jan
#this function is useful to see quickly the missing months for a given series
check_month_availabilty <- function(ns){
  table(recruitment_subset$month_in_season[recruitment_subset$ser_nameshort==ns],
        recruitment_subset$season[recruitment_subset$ser_nameshort==ns])
}
```

### Reason for exclusion
* Bann: no monthly data available
* BeeG: Monitoring starts in April while migration is already high
* BroE: same data as BroG but for elvers
* Burr: temporal coverage is very variable and it is very difficult to locate the duration of the peak
* Erne: sampling starts in March while migration is already rather high
* Fla, FlaE and FlaG: twice the same series. Monitoring stards in May while abundance is sometimes already high
* Isle_G: limited number of seasons with a perhaps too limited monthly coverage
* RhDOG: only 3 months per year, moreover, there are sometimes sevaral values per month in the same year
* StGeE: same as stGeG but for elvers
* Stra: no monthly data



### Reason for keeping
* BroG: Monitoring starts in may but often with a zero catch, and continues till the end of the season. Only 2012 should be removed given comments
* EmsB: While the number of sampled months is limited, it seems to appropriately covers the peak
* EmsH: While the number of sampled months is limited, it seems to appropriately covers the peak
* GarG: adequate monthly coverage
* GiSc: adequate monthly coverage, already used by the WGEEL
* Grey: perhaps a bit upstream (have to check for the presence of a fishery downstream) but very good monthly coverage
* ImsaGY: very good coverage, already used by the WGEEL
* Liff: the two seasons starting in March appears to be appropriate
* ShaE: in 2012, monitoring starts in March leading to a good coverage of the whole season, for other years, it starts too late (May or latter)
* ShiF and ShiM: traps running all years long therefore good coverage of the migration wave.
* StGeG: only one year of data but good coverage of the migration wave (from march to october)

### to be discussed
* Oria: first, monthly coverage in a bit limited (october and february represent 10% of yearly catches each), moreover, the GLM model included a month effect so the monthly pattern is similar every year by construction (as such, we should only consider one year). ESTI. OK. We could provide real densities (GE/m3) if you think that including more years could help.


### Final selection of data
Given selection of data, we make a subset of data:
```{r}
recruitment_subset <- subset(recruitment, recruitment$ser_nameshort %in%
                               c("BroG", "EmsB", "EmsH",
                                 "GarG", "GiSc", "Grey",
                                 "ImsaGY", "Liff", "ShaE",
                                 "ShiF", "StGeG","Oria"))
#remove 2012 for BroG
recruitment_subset <- subset(recruitment_subset,
                             recruitment_subset$ser_nameshort != "BroG" | 
                               recruitment_subset$season != 2012)

# keep all for EmsB
# remove seasons 2015 and 2016 
recruitment_subset <- subset(recruitment_subset,
                             recruitment_subset$ser_nameshort != "EmsH" | 
                               (!recruitment_subset$season %in% 2015:2016))

#GarG: we keep all years
#GiSc: remove 1991 (nov dec missing), 1998, 2003, 2015 (january missing) and
# 2014 (february missing)
recruitment_subset <- subset(recruitment_subset,
                             recruitment_subset$ser_nameshort != "GiSc" | 
                               (!recruitment_subset$season %in% c(1991,1998,
                                                                  2003,2014,
                                                                  2015,2020)))
#Grey: we removd 2018
recruitment_subset <- subset(recruitment_subset,
                             recruitment_subset$ser_nameshort != "Grey" | 
                               recruitment_subset$season != 2018)
#ImsaGY we removed 2020
recruitment_subset <- subset(recruitment_subset,
                             recruitment_subset$ser_nameshort != "ImsaGY" | 
                               recruitment_subset$season != 2020)

#Liff: we keep the two seasons starting in march (month 5)
recruitment_subset <- subset(recruitment_subset,
                             recruitment_subset$ser_nameshort != "Liff" | 
                               recruitment_subset$season %in% c(2017, 2019))

#ShaE: we keep only 2012
recruitment_subset <- subset(recruitment_subset,
                             recruitment_subset$ser_nameshort != "ShaE" | 
                               recruitment_subset$season == 2012)
#Shif: remove 2020
recruitment_subset <- subset(recruitment_subset,
                            (!recruitment_subset$ser_nameshort %in% c("ShiF","ShiM")) | 
                               recruitment_subset$season != 2020)

#StGeG we keep the single year
recruitment_subset <- subset(recruitment_subset,
                            (!recruitment_subset$ser_nameshort %in% c("StGeG")) | 
                               recruitment_subset$season != 2020)
#Oria, we keep season 2006 (before EMP) and 2018 (after EMP) just to show that 
#seasonality hasn't changed
recruitment_subset <- subset(recruitment_subset,
                            recruitment_subset$ser_nameshort != "Oria" | 
                               recruitment_subset$season %in% c(2006,2018))
```



## Data preparation
To run the model, we need a table in the wide format: one column per month, one row for a year x time series. It leads to a dataset with 82 rows.

```{r}
#we build a table with one row per season and one column per month (1:january)
recruitment_subset$emu <- ser2$ser_emu_nameshort[match(recruitment_subset$ser_nameshort,
                                                       ser2$ser_nameshort)]
recruitment_wide <- pivot_wider(data=recruitment_subset[, c("ser_nameshort",
                                                            "emu",
                                                     "country",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(recruitment_wide)[-(1:4)] <- paste("m",
                                        names(recruitment_wide)[-(1:4)],
                                        sep="")
```

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months, and we compute proportions per month for each year.

```{r}
recruitment_wide <- recruitment_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
recruitment_wide[, -(1:4)] <- recruitment_wide[, -(1:4)] + 1e-3
total_catch_year <- rowSums(recruitment_wide[, paste("m", 1:12, sep="")])
recruitment_wide <- recruitment_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
recruitment_wide$period <- ifelse(recruitment_wide$season>2009,
                                  2,
                                  1)

table(recruitment_wide$period,
       recruitment_wide$ser_nameshort)
```
Only 4 series have data in the first period therefore period comparisons will be difficult. However, can now try to fit the model.

## Running the model
```{r}
group <- as.integer(interaction(recruitment_wide$ser_nameshort,
                                            recruitment_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(recruitment_wide[, paste("m", 1:12, sep="")])


build_data <- function(nbclus,seuil=.95){
  ref=as.integer(
         names(nb_occ_group)[which(nb_occ_group==max(nb_occ_group))])[1]
  list(y=y, #observations
       y2=y,
       group=group, #group identifier (a group is a period x series)
       nbm=12, #number of month
       nbclus=nbclus,# number of clusters
       seuil=seuil,
       nbgroup=length(unique(group)),
       nbobs=nrow(y),
       ref=ref,
       not_ref=seq_len(length(unique(group)))[-ref]
       )
}

generate_init <- function(nbclus,mydata){
  lapply(1:3,function(nclus){
    dirichlet_prior <- function(n){
      t(replicate(n,{tmp <- runif(12)
        tmp <- tmp / sum(tmp)
      }))
    }
    cluster <- sample(1:nbclus, length(unique(group)), replace=TRUE)
    cluster[mydata$ref] <- NA
    list(cluster=cluster,
         esp_unordered=dirichlet_prior(nbclus),
         alpha_group=dirichlet_prior(length(unique(group))),
        lambda=runif(1,2,3)
    )
  })
}
```

Now, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
comparison <- lapply(2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         res <- run.jags("jags_model.txt", monitor= "deviance",
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=10000,n.chains=3,
                      inits=generate_init(nbclus, mydata),
                      data=mydata)
         res_mat <- as.matrix(as.mcmc.list(res))
         mean(res_mat[,1])-0.5*var(res_mat[,1])
       })
best_recruitment <- data.frame(nbclus=2:7,dic=unlist(comparison))
```

```{R}
load("recruitment_jags.rdata")
best_recruitment
```

Best solutions arise with 3 clusters, therefore we explore go further with this value.


```{r, eval=FALSE}
nbclus <- 3
mydata <-build_data(3)
myfit_recruitment <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=3, thin=5,
                      inits=generate_init(nbclus, mydata), data=mydata)
save(myfit_recruitment, best_recruitment,
     file="recruitment_jags.rdata")
```

## Results
Once fitted, we can plot monthly pattern per cluster
```{r}
load("recruitment_jags.rdata")
nbclus <- 3
mydata <-build_data(3)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}


ggplot(get_pattern_month(myfit_recruitment),aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  theme_bw()


```

We compute some statistics to characterize the clusters.
```{r}
#function to make circular shifting
shifter <- function(x, n = 1) {
     if (n == 0) x else c(tail(x, -n), head(x, n))
}


characteristics <- function(myres,nbclus, threshold=.80){
  mydata <- as.matrix(as.mcmc.list(myres))
  sapply(seq_len(nbclus),function(clus){
    esp <- mydata[, paste("esp[",clus , ",", 1:12, "]", sep="")]
    duration_it <- apply(esp, 1, function (esp_it){
      esp_it <- min(which(cumsum(sort(esp_it, decreasing=TRUE))/
                            sum(esp_it)>threshold))
    })
    duration <- quantile(duration_it, probs=c(0.025, .5, .975))
    month_prop <- colMeans(esp)
    peak <- which(month_prop == max(month_prop))
    
    season_order <- shifter(1:12,peak-6) #with this order peak in the middle
                                         #of the season
    
    centroids <- apply(esp[,season_order], 1 , function(esp_it) {
      sum(esp_it * 1:12)/sum(esp_it)
    })
    quant_centr <- quantile(centroids, probs=c(0.025, .5, .975))
    quant_centr <- quant_centr - ceiling(quant_centr) +
      season_order[ceiling(quant_centr)]
    data.frame(cluster=clus,
               duration=duration[2],
               duration2.5=duration[1],
               duration97.5=duration[3],
               centroid=quant_centr[2],
               centroid2.5=quant_centr[1],
               centroid97.5=quant_centr[3])
   
  })
}
t(as.data.frame(characteristics(myfit_recruitment, 3)))
```
Duration indicates the minimum number of months that covers 80% of the wave (1st column is the median, and the 2 next one quantiles 2.5% and 97.5% of credibility intervals). Centroid is the centroid of the migration wave (e.g. 11.5 would indicate a migration centred around mid november). The first column is the median and the two next one the quantiles 2.5 and 97.5%.

We can also look at the belonging of the different groups.
```{r}
get_pattern_month <- function(res,mydata){
  
  groups <- interaction(recruitment_wide$ser_nameshort,
                                            recruitment_wide$period,
                                            drop=TRUE)
  group_name <- levels(groups)
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", "clus1", "clus2","clus3")
  cbind.data.frame(data.frame(ser=ser, period=period),
                   classes)
}

myclassif <- get_pattern_month(myfit_recruitment)
print(myclassif[order(myclassif$cluster),])
```
The 3rd cluster corresponds to series from the Southern Europe, whatever the period. Cluster 2 corresponds to North Europe. Cluster 1 corresponds to EmsH which appears to be slightly atypical. However, clusters 1 and 2 are quite similar and many series x periods are attributed with high occurences in both clusters 2 and 3. These results confirm the spatial pattern in recruitment seasonality and highlight that no major changes have occured after 2010.

Showing it on a map:

```{r}
library(sf)
myclassif$x <- ser2$ser_x[match(myclassif$ser, ser2$ser_nameshort)]
myclassif$jit_x <- jitter(myclassif$x,amount=.5)
myclassif$y <- ser2$ser_y[match(myclassif$ser, ser2$ser_nameshort)]
myclassif$jit_y <- jitter(myclassif$y,amount=.5)
cou <- st_read("/mnt/SIG/01-REFERENTIELS/LIMITES_ADMINISTRATIVES_monde/european_countries_WGS84.shp")
cou <- st_transform(cou, crs=4326)
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_point(data=myclassif,aes(x=jit_x,y=jit_y,col=as.factor(cluster))) +
  scale_fill_brewer() +theme_bw() +xlim(-20,30) + ylim(35,65)
```


# Silver eel
## Data availability
There are 87 pure silver eel dataseries, this has several consequences:
* Given the high number of time series, we will only focus one pure silver eels data series and neglect YS data series (except if a data provider clearly tells us that we can add this data)
* We have to develop criterion to quickly check the reliability of the data and makes a quick sorting of the data.


##Data correction

Some corrections of errors found in the database
```{r}
###wrong year for BurS time series (january 1972 instead of 1973)

## corrected by Cedric directly in original files
# res$das_year[res$ser_nameshort == "BurS" &
#                       res$das_year == 1972 &
#                       res$das_month == 1 &
#                       res$das_value ==95 ] <- 1973
# 
# #for MajT, year 1987 is missing while there are duplicates for year 1989 
# res$das_year[res$ser_nameshort == "MajT" &
#                res$das_year == 1989 &
#                res$das_month == 11 &
#                res$das_value==1] <- 1987
# res$das_year[which(res$ser_nameshort == "MajT" &
#                res$das_year == 1989 &
#                res$das_month == 10 &
#                res$das_value==1)[1]] <- 1987
# res$das_year[res$ser_nameshort == "MajT" &
#                res$das_year == 1989 &
#                res$das_month < 10 &
#                res$das_month >5 ] <- 1987
# res$das_year[res$ser_nameshort == "MajT" &
#                res$das_year == 1989 &
#                res$das_month == 5 &
#                res$das_value==7] <- 1987
# #same series: confusion between 1991 and 1994
# res$das_year[res$ser_nameshort == "MajT" &
#                res$das_year == 1994 &
#                res$das_month == 5 &
#                res$das_value == 3] <- 1991
# res$das_year[res$ser_nameshort == "MajT" &
#                res$das_year == 1994 &
#                res$das_month == 11 &
#                res$das_value == 1] <- 1991
# 
# ###For Scorf, there are two data in June, we sum the two points
# scorf <- res %>%
#   filter(ser_nameshort == "ScorS", das_month == 6) %>%
#   group_by_at(vars(-one_of("das_value"))) %>%
#   summarise(das_value=sum(das_value))
# 
# res <- bind_rows(
#   res %>%
#   filter(res$ser_nameshort != "ScorS" | res$das_month != 6),
#   scorf)
# 
# ##Souston year typo
# res$das_year[res$ser_nameshort == "SouS" &
#                res$das_year == 2018 &
#                res$das_month == 12 &
#                res$das_value == 6060] <- 2017
  

#for WarS, data are separated in males and females, we merge both dataset
table(res$das_month[res$ser_nameshort == "WarS"],
      res$das_year[res$ser_nameshort == "WarS"])

WarS <- res %>%
   filter(ser_nameshort == "WarS", !is.na(das_effort)) %>%
   group_by_at(vars(-one_of(c("das_comment","das_value")))) %>%
   summarise(das_value=sum(das_value))
 
res <- bind_rows(
   res %>%
   filter(res$ser_nameshort != "WarS"),
   WarS)


```

## Data selection
As for glass eel, we start by defining season consistent with ecological knowledge on migration. Downstream runs of European silver eels typically start in the autumn and may last until early spring (Brujs and Durif 2009), but we saw during WGEEL 2019 that peak in silver catches in Sweden is centered around August/September. Therefore, it is difficult to split season of migration in a similar way for all Europe. Therefore, we define a season of migration per series: we look to the month corresponding to the peak and at the month with the lowest catches. The month with lowest catch fmin define the beggining of the season (month_in_season=1) and season y stands for the 12 months from fmin y (e.g., if lowest migration is in december, season ranges from december to november, and season y denotes season from december y to november y+1).
```{r}
#creating season
finding_peak <- function(data){
  mean_per_month <- tapply(data$das_value,list(data$das_month),mean,na.rm=TRUE)
  peak_month <-as.integer(names(sort(mean_per_month,decreasing=TRUE)))[1]
  peak_month
}

finding_lowest_month <- function(data){
  mean_per_month <- tapply(data$das_value,list(data$das_month),mean,na.rm=TRUE)
  lowest_month <-as.integer(names(sort(mean_per_month)))[1]
  lowest_month
}


season_creation<-function(data){
  peak_month <- finding_peak(data) #2 3 4 5 6 7 8 9 10 11 12 1
  lowest_month <- finding_lowest_month(data)
  #season_order <- shifter(1:12,peak_month-6)
  season_order <- shifter(1:12,lowest_month-1)
  data$month_in_season <- as.factor(match(data$das_month,season_order))
  data$season <- ifelse(data$das_month < lowest_month,
                        data$das_year-1,
                        data$das_year)
  data$peak_month <- peak_month
  data$lowest_month <- lowest_month
  data
}

silvereel <- do.call("rbind.data.frame",
                     lapply(ser2$ser_nameshort[ser2$ser_lfs_code=="S"],
                            function(s)
                              season_creation(res[res$ser_nameshort==s,])))
months_peak_per_series<- unique(silvereel[,c("ser_nameshort","peak_month")])
table(months_peak_per_series$peak_month)
```
This confirms that most series peak in autumn, but that other peak in spring or summer.



## Building diagnostics of quality for series
```{r}
#to be considered as valid, we need:
#   at least 8 months including the peak (since there are often two peaks, one
#   in spring and one in autumn)
#   that the first month of data generally stands for a small proportion of catches
#   that the last month of data generally stands for a small proportion of catches
#   that there is no missing month between first and last month

good_coverage_wave <- function(mydata){
  
  checking_duplicate(mydata)
  peak_month <- unique(mydata$peak_month)
  lowest_month <- unique(mydata$lowest_month)
  original_months <- shifter(1:12,lowest_month-1)
  #we put data in wide format with one row per seasaon
  
  data_wide <- mydata[,c("season",
                       "month_in_season",
                       "das_value")] %>%
                      spread(month_in_season,
                           das_value,
                           drop=FALSE)
  data_wide <- data_wide[,c(1:12,"season")]
  mean_per_month <- colMeans(data_wide[,1:12],na.rm=TRUE)
  mean_per_month <- mean_per_month / sum(mean_per_month, na.rm=TRUE)
  
  cum_sum <- 
    cumsum(sort(mean_per_month, decreasing=TRUE)) / 
    sum(mean_per_month, na.rm=TRUE)
  
  #we take the last month to have at least 95% of catches and which stands for
  #less than 10 % of catches
  bound <- min(which(cum_sum > .95 &
                         mean_per_month[as.integer(names(cum_sum))]<.05))
  if (is.infinite(bound) | sum(is.na(mean_per_month))>6){
    print(paste("For",
                unique(mydata$ser_nameshort),
                "not possible to define a season"))
    return (NULL)
  }
    
  min_max <- range(as.integer(names(cum_sum)[1:bound]))
  fmin  <- min_max[1]
  lmin <- min_max[2]
  
  if ((fmin>1 & mean_per_month[fmin]>.05 & is.na(mean_per_month[fmin+1])) |
      (lmin<12 & mean_per_month[lmin]>.05 & is.na(mean_per_month[lmin+1]))){
        print(paste("For",
                unique(mydata$ser_nameshort),
                "not possible to define a season"))
        return (NULL)
    
  }
    
  
  print(paste("For ",
              unique(mydata$ser_nameshort),
              " a good season should cover months:",
              original_months[fmin],
              "to",
              original_months[lmin]))
  
#  if ((lmin - fmin) < 8) return(NULL)
  keeping <- data_wide%>%
    mutate(num_na=rowSums(is.na(select(.,num_range("",fmin:lmin))))) %>%
    filter(num_na==0)
  if (nrow(keeping)==0) return(NULL)
  keeping$season
}

checking_duplicate <- function(mydata){
  counts_data <- table(mydata$das_year, mydata$das_month)
  if (sum(counts_data > 1)) {
    dup <- which(counts_data > 1, arr.ind = TRUE)
    print(paste("##duplicates series",unique(mydata$ser_nameshort)))
    stop(paste(rownames(counts_data)[dup[,1]],
               colnames(counts_data)[dup[, 2]],
               collapse = "\n"))
  }
}
```


The previous function looks at different criterion: it put the data in the wide format and check if we have at least 3 months around the peak.  Moreover, it seeks for two extreme months when the cumulative catch is below 10%. If there is now missing month between these two extreme months, the season is kept. Using this function, we can make a preliminary screening of available series.

```{r, warning=FALSE}
kept_seasons <- lapply(unique(silvereel$ser_nameshort), function(s){
  sub_silver <- subset(silvereel, silvereel$ser_nameshort==s)
  good_coverage_wave(sub_silver)
})
```

Finally, here are the series kept given previous criterion.
```{r}
names(kept_seasons) <- unique(silvereel$ser_nameshort)
#we removeDaugS since the number of caught eel is too limited to work on
#seaonality (4, 0 , 8 from 2017 to 2019)
#kept_seasons[["DaugS"]] <- NULL

kept_seasons[!sapply(kept_seasons,is.null)]

```

## Data preparation
To run the model, we need a table in the wide format: one column per month, one row for a year x time series. 

```{r}
silvereel_subset <- subset(silvereel, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, silvereel$season, silvereel$ser_nameshort))

silvereel_subset$emu <- ser2$ser_emu_nameshort[match(silvereel_subset$ser_nameshort,
                                                       ser2$ser_nameshort)]

silvereel_wide <- pivot_wider(data=silvereel_subset[, c("ser_nameshort",
                                                            "emu",
                                                     "country",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(silvereel_wide)[-(1:4)] <- paste("m",
                                       names(silvereel_wide)[-(1:4)],
                                       sep="")
```

It leads to a dataset with `r nrow(silvereel_wide)` rows. Since seasons are not comparable among series, we keep calendar months (eg: 12 for decembre, not month in season), while rows indeed correspond to seasons.


We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months, and we compute proportions per month for each year.

```{r}
silvereel_wide <- silvereel_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
silvereel_wide[, -(1:4)] <- silvereel_wide[, -(1:4)] + 1e-3
total_catch_year <- rowSums(silvereel_wide[, paste("m", 1:12, sep="")])
silvereel_wide <- silvereel_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
silvereel_wide$period <- ifelse(silvereel_wide$season>2009,
                                  2,
                                  1)

table(silvereel_wide$period,
       silvereel_wide$ser_nameshort)
```
The situation is better for silver eel than for glass eel, we have a good sets of time series with data both before and after 2009.


## Running the model
```{r}
group <- as.integer(interaction(silvereel_wide$ser_nameshort,
                                            silvereel_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(silvereel_wide[, paste("m", 1:12, sep="")])
```

Know, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
comparison <- lapply(2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         res <- run.jags("jags_model.txt", monitor= "deviance",
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=100000,n.chains=3,
                      inits=generate_init(nbclus, mydata),
                      data=mydata)
         res_mat <- as.matrix(as.mcmc.list(res))
         mean(res_mat[,1])+0.5*var(res_mat[,1])
       })
best_silver <- data.frame(nbclus=2:7,dic=unlist(comparison))
```

```{R}
load("silver_jags.rdata")
best_silver
```

Best solutions arise with 3 clusters, therefore we explore go further with this value.


```{r, eval=FALSE}
nbclus <- 3
mydata <-build_data(3)
myfit_silver <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster", "centroid",
                                            "centroid_group",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "centroid"),
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=200000,n.chains=3, thin=5,
                      inits=generate_init(nbclus, mydata), data=mydata)
save(myfit_silver, best_silver,
     file="silver_jags.rdata")
```

##Results
Once we fitted, we can plot monthly pattern per cluster
```{r}
load("silver_jags.rdata")
nbclus <- 3
mydata <-build_data(3)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}


ggplot(get_pattern_month(myfit_silver),aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  theme_bw()
```
We have 3 clusters: cluster 2 corresponds to a migration wave starting in late spring and ending in late autumn, cluster 3 corresponds to a migration wave really centered around october, anc cluster 1 corresponds to a migration wave starting october with a wave that can last a little bit during winter.

```{r}
t(as.data.frame(characteristics(myfit_silver, 3)))
```

We can look at the belonging of the different groups.
```{r}
get_pattern_month <- function(res,mydata){
  
  groups <- interaction(silvereel_wide$ser_nameshort,
                                            silvereel_wide$period,
                                            drop=TRUE)
  group_name <- levels(groups)
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  country <- ser2$ser_cou_code[match(ser, ser2$ser_nameshort)]
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", "clus1", "clus2","clus3")
  cbind.data.frame(data.frame(ser=ser, period=period, country=country),
                   classes)
}

myclassif_silver <- get_pattern_month(myfit_silver)
print(myclassif_silver[order(myclassif_silver$cluster),])
table(myclassif_silver$country, myclassif_silver$cluster)
```
The spatial pattern is less obvious than for glass eel. However, looking at the map, we see that clusters 1 and 
3, which display similar seasonality, are more located on the Western coasts of Europe (with most cluster 3 in the south, and most clusters 1 in the north), whereas, cluster 2 is more located in North-Sea and Baltic Sea, with the notable exception of the Imsa dataseries. Once again, no difference between periods are observed.

```{r}
library(sf)
myclassif_silver$x <- ser2$ser_x[match(myclassif_silver$ser, ser2$ser_nameshort)]
myclassif_silver$jit_x <- jitter(myclassif_silver$x,amount=.5)
myclassif_silver$y <- ser2$ser_y[match(myclassif_silver$ser, ser2$ser_nameshort)]
myclassif_silver$jit_y <- jitter(myclassif_silver$y,amount=.5)
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_point(data=myclassif_silver,aes(x=jit_x,y=jit_y,col=as.factor(cluster))) +
  scale_fill_brewer() +theme_bw() +xlim(-20,30) + ylim(35,65)
```


# Yellow eel
## Data availability
There are 32 time series, i.e. more than for glass eels but less than for silver eels. It may be worthwile pooling some of the 6 YS series if the proportions of silver eels is not too important.

```{r}
ser2[ser2$ser_lfs_code=="YS", c("ser_nameshort", "ser_emu_nameshort", "ser_comment", "ser_locationdescription")]
```
GVT, Sakt and ZeiT are fishery based and fishery takes place only 2 months per year so we can't keep the data.

```{r}
table(res$das_year[res$ser_nameshort %in% c('ALA', 'LakT', 'KER')],
      res$das_month[res$ser_nameshort %in% c('ALA', 'LakT', 'KER')],
      res$ser_nameshort[res$ser_nameshort %in% c('ALA', 'LakT', 'KER')])
```
For ALA and KER, we only have one month of data, so we do not keep the data. LakT is a good candidate, however, it is noted that there are 8 months of monitoring per year while in the data, we have more data missing, therefore it is currently not possible to know whether a missing data stands for zero or no data. Moreover, looking at comment, it seems to correspond to migrating eels, i.e. an important proportion of silver eels. Therefore, we discard also this data series.

##Data correction
We have found some errors in series "MorE" and "VaccY" but don't know how to fix the mystakes, so currently, we remove them from our selection.

## Data selection
As for other stages, we start by defining season consistent with ecological knowledge on migration. However, there is no migration for yellow eels and peaks in data correspond more to seasonal a peak in activity. We have few information on the seasonality of yellow eels, therefore, similarly to silver eel, it is difficult to split season of migration in a similar way for all Europe. Therefore, we define a season of migration per series using the same procedure as for silver eels: the month with lowest activity fmin define the beggining of the season (month_in_season=1) and season y stands for the 12 months from fmin y (e.g., if lowest activity is in december, season ranges from december to november, and season y denotes season from december y to november y+1). 

```{r}
yelloweel <- do.call("rbind.data.frame",
                     lapply(ser2$ser_nameshort[ser2$ser_lfs_code=="Y"],
                            function(s)
                              season_creation(res[res$ser_nameshort==s,])))
months_peak_per_series<- unique(yelloweel[,c("ser_nameshort","peak_month")])
table(months_peak_per_series$peak_month)
```
Peaks of activity range from may to november. It might be possible to define a common season from february/march to january/february, but we prefer not imposing it without more precise information.


## Building diagnostics of quality for series
We used the functions used for silver eels to assess whether a time series offer a good coverage of a season of activity (e.g. good_coverage_wave and check_duplicate). 

```{r, warning=FALSE}
kept_seasons <- lapply(unique(yelloweel$ser_nameshort[!yelloweel$ser_nameshort %in%c("MorE","VaccY")]), function(s){
  sub_yellow <- subset(yelloweel, yelloweel$ser_nameshort==s)
  good_coverage_wave(sub_yellow)
})
```

Finally, here are the series kept given previous criterion.
```{r}
names(kept_seasons) <- unique(yelloweel$ser_nameshort[!yelloweel$ser_nameshort %in%c("MorE","VaccY")])
kept_seasons[!sapply(kept_seasons,is.null)]
```
## Data preparation
We carry out the same procedure a for other stages. 

```{r}
yelloweel_subset <- subset(yelloweel, 
                           mapply(function(season, series){
                             season %in% kept_seasons[[series]]
                           }, yelloweel$season, yelloweel$ser_nameshort))

yelloweel_subset$emu <- ser2$ser_emu_nameshort[match(yelloweel_subset$ser_nameshort,
                                                       ser2$ser_nameshort)]

yelloweel_wide <- pivot_wider(data=yelloweel_subset[, c("ser_nameshort",
                                                            "emu",
                                                     "country",
                                                     "season",
                                                     "das_month",
                                                     "das_value")],
                                names_from="das_month",
                                values_from="das_value")
names(yelloweel_wide)[-(1:4)] <- paste("m",
                                       names(yelloweel_wide)[-(1:4)],
                                       sep="")
###we coun't the number of zeros per lines to remove lines without enough
###fishes
data_poor <- data.frame(yelloweel_wide$ser_nameshort,
                        yelloweel_wide$season,
                  zero=rowSums(yelloweel_wide[, -(1:4)] == 0, na.rm=TRUE),
           tot=rowSums(yelloweel_wide[, -(1:4)], na.rm=TRUE))
data_poor %>% filter(tot<100)
```
Given the limited number of eels caught in DaugY in 2018, we remove this series.

```{r}
yelloweel_wide <- yelloweel_wide %>%
  filter(ser_nameshort != "DaugY" | season != 2018)
```

It leads to a dataset with `r nrow(yelloweel_wide)` rows. Since seasons are not comparable among series, we keep traditional month (eg: 12 for decembre, not month in season), while rows indeed correspond to seasons.

We now replace NA value per zero since we selected our dataseries with missing months corresponding to insignificant months, and we compute proportions per month for each year.

```{r}
yelloweel_wide <- yelloweel_wide %>%
  replace_na(replace=list(m1=0,
                          m2=0,
                          m3=0,
                          m4=0,
                          m5=0,
                          m6=0,
                          m7=0,
                          m8=0,
                          m9=0,
                          m10=0,
                          m11=0,
                          m12=0))
yelloweel_wide[, -(1:4)] <- yelloweel_wide[, -(1:4)] + 1e-3
total_catch_year <- rowSums(yelloweel_wide[, paste("m", 1:12, sep="")])
yelloweel_wide <- yelloweel_wide %>%
  mutate_at(.vars=paste("m",1:12,sep=""),function(x) x/total_catch_year)
```

The Commission asks us to compare the pattern before and after 2007, probably to see the effect of the Eel Regulation. It is therefore necessary to build a period index. However, since most countries implemented their EMPs only in 2009/2010, we split in 2010.

```{r}
yelloweel_wide$period <- ifelse(yelloweel_wide$season>2009,
                                  2,
                                  1)

table(yelloweel_wide$period,
       yelloweel_wide$ser_nameshort)
```
The situation is an intermediate between glass eel and silver eel.


## Running the model
```{r}
group <- as.integer(interaction(yelloweel_wide$ser_nameshort,
                                            yelloweel_wide$period,
                                            drop=TRUE))
nb_occ_group <- table(group)
y <-as.matrix(yelloweel_wide[, paste("m", 1:12, sep="")])
```

Know, we make a loop to select the number of clusters based on a DIC criterion

```{r, eval=FALSE}
comparison <- lapply(2:7,
       function(nbclus){
         mydata <- build_data(nbclus)
         res <- run.jags("jags_model.txt", monitor= "deviance",
                      summarise=FALSE, adapt=20000, method="parallel",
                      sample=10000,burnin=100000,n.chains=3,
                      inits=generate_init(nbclus, mydata),
                      data=mydata)
         res_mat <- as.matrix(as.mcmc.list(res))
         mean(res_mat[,1])+0.5*var(res_mat[,1])
       })
best_yellow <- data.frame(nbclus=2:7,dic=unlist(comparison))
save(best_yellow, file="yellow_jags.rdata")
```

```{R}
load("yellow_jags.rdata")
best_yellow
```

Best solutions arise with 5 clusters, more than for other stages.


```{r, eval=FALSE}
nbclus <- 5
mydata <-build_data(nbclus)
myfit_yellow <- run.jags("jags_model.txt", monitor= c("cluster", "esp", "alpha_group",
                                            "cluster",
                                            "distToClust", "duration_clus",
                                            "duration_group",
                                            "lambda","id_cluster",
                                            "distFromRef"),
                      summarise=FALSE, adapt=50000, method="parallel",
                      sample=10000,burnin=200000,n.chains=3, thin=5,
                      inits=generate_init(nbclus, mydata), data=mydata)
save(myfit_yellow, best_yellow,
     file="yellow_jags.rdata")
```

## Results
Once we fitted, we can plot monthly pattern per cluster
```{r}
load("yellow_jags.rdata")
nbclus <- 5
mydata <-build_data(nbclus)
get_pattern_month <- function(res,type="cluster"){
  res_mat <- as.matrix(as.mcmc.list(res))
  if (type=="cluster"){
    sub_mat <- as.data.frame(res_mat[,grep("esp",colnames(res_mat))])
  }
  sub_mat <- sub_mat %>% 
    pivot_longer(cols=1:ncol(sub_mat),
                 names_to="param",
                 values_to="proportion")
  tmp <- lapply(as.character(sub_mat$param),function(p) strsplit(p,"[[:punct:]]"))
  sub_mat$cluster<-as.factor(
    as.integer(lapply(tmp, function(tt) tt[[1]][2])))
  sub_mat$month <- as.character(lapply(tmp,
                                       function(tt) paste("m",
                                                          tt[[1]][3],
                                                          sep="")))
  sub_mat$month <- factor(sub_mat$month, levels=paste("m", 1:12, sep=""))
  sub_mat
}


ggplot(get_pattern_month(myfit_yellow),aes(x=month,y=proportion))+
  geom_boxplot(aes(fill=cluster),outlier.shape=NA) +
  theme_bw()
```

```{r}
t(as.data.frame(characteristics(myfit_yellow, 5)))
```

Cluster 5 corresponds to a migration 5 concentrated in june and july. Cluster 2 is a bit similar, but more widespread from may august. Cluster 1 latter with hight proportion in late summer / early autumn. Clusters 3 and 4 are quite similar with widespread waves centered around summer and eraly autumn, with cluster 3 more widepread than cluster 4.


We can look at the belonging of the different groups.
```{r}
get_pattern_month <- function(res,mydata){
  
  groups <- interaction(yelloweel_wide$ser_nameshort,
                                            yelloweel_wide$period,
                                            drop=TRUE)
  group_name <- levels(groups)
  tmp <- strsplit(as.character(group_name),
                  "\\.")
  ser <- as.character(lapply(tmp,function(tt){
    tt[1]
  }))
  country <- ser2$ser_cou_code[match(ser, ser2$ser_nameshort)]
  period <- as.character(lapply(tmp,function(tt){
    tt[2]
  }))
  res_mat <- as.matrix(as.mcmc.list(res))
  
  clus <- t(sapply(seq_len(length(unique(groups))), function(id){
    name_col <- paste("cluster[",id,"]",sep="")
    freq <- table(res_mat[,name_col])
    max_class <- names(freq)[order(freq,decreasing=TRUE)[1]]
    c(max_class,freq[as.character(1:nbclus)])
  }))
  storage.mode(clus) <- "numeric"
  classes <- as.data.frame(clus)
  names(classes) <- c("cluster", "clus1", "clus2","clus3")
  cbind.data.frame(data.frame(ser=ser, period=period, country=country),
                   classes)
}

myclassif_yellow <- get_pattern_month(myfit_yellow)
print(myclassif_yellow[order(myclassif_yellow$cluster),])
table(myclassif_yellow$country, myclassif_yellow$cluster)
```
There is no clear spatial pattern in the clustering. This is not necessarily surprising: eels display an ontongenic shift during their life stage, from a migratory behaviour towards sedentary behaviour (Imbert et al. 2010). Consequently, given the predominence of younger or older eels, which vary depending on the position in the river basin, a series may correspond to a seasonality of migration, to a seasonality of activity of sedentary eels, or to a mixture of both. Moreover, environmental conditions that trigger migration or activity may also vary depending on the position in the river basin and complexify the comparison of the time series. The sampling method may also alter the results: many time series are collected upstream fishways, and the attractivity / passability of those fishway vary among seasons.

```{r}
library(sf)
myclassif_yellow$x <- ser2$ser_x[match(myclassif_yellow$ser, ser2$ser_nameshort)]
myclassif_yellow$jit_x <- jitter(myclassif_yellow$x,amount=.5)
myclassif_yellow$y <- ser2$ser_y[match(myclassif_yellow$ser, ser2$ser_nameshort)]
myclassif_yellow$jit_y <- jitter(myclassif_yellow$y,amount=.5)
ggplot(data = cou) +  geom_sf(fill= "antiquewhite") +
		geom_point(data=myclassif_yellow,aes(x=jit_x,y=jit_y,col=as.factor(cluster))) +
  scale_fill_brewer() +theme_bw() +xlim(-20,30) + ylim(35,65)
```